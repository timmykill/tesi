\documentclass[12pt,a4paper,twoside]{book}
\usepackage[english]{babel}
\usepackage{tikz}
\usetikzlibrary{arrows.meta,calc,decorations.markings,shapes.misc}
\usepackage[utf8]{inputenc}
\usepackage[a4paper,inner=3.5cm,outer=2.5cm]{geometry}
\usepackage[titletoc,title,toc,page]{appendix}
\usepackage{wrapfig}
\usepackage{cite}
\usepackage{url}
\usepackage{hyphenat}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{mathrsfs}
\usepackage{mathpartir}
\usepackage[only,fatsemi]{stmaryrd}
\usepackage{graphicx}
\usepackage{bm}
\usepackage{listings}
\usepackage{stmaryrd}
\usepackage{upgreek}

\lstset{
  basicstyle=\ttfamily,
  breaklines=true,
  captionpos=b
}

\tikzset{
  >=Stealth,
  lab/.style={midway,fill=white,inner sep=2pt},
  markarrows/.style={
    postaction={decorate},
    decoration={markings,
      mark=at position .85 with {\arrow{Stealth}},
      mark=at position 1 with {\arrow{Stealth}}}
  }
}

\newcommand{\rom}[1]{\uppercase\expandafter{\romannumeral #1\relax}}
\newcommand{\metaDeff}{\mathrel{\mathop{::}}=}
\newcommand{\metaDef}{\mathrel{\mathop:}=}
\newcommand{\tlint}[1]{\tau@#1}
\newcommand{\tlthen}[1]{#1\text{.then}}
\newcommand{\tlelse}[1]{#1\text{.else}}
\newcommand{\gencom}{p.e \rightarrow q.x}
\newcommand{\gensel}{p \rightarrow q[L]}
\newcommand{\pn}{\mathrm{pn}}
\newcommand{\llbracket}{[\![}
\newcommand{\rrbracket}{]\!]}
\newcommand{\MCL}{\mathscr{L}}
\newcommand{\qed}{\hfill\square}
\newcommand{\heart}{\heartsuit}


\begin{document}
\pagestyle{empty}
\newgeometry{
    left=20mm,
    right=20mm,
    top=20mm,
    bottom=20mm
}

\begin{titlepage}
\begin{center}

\includegraphics[width=6.5cm,height=4.7cm]{img/marchio-di-ateneo.png}

\vspace{10mm}
{\large{\bf{Scuola di Scienze}}}\\
\vspace{5mm}
{\Large{\bf{Corso di Laurea Magistrale in Informatica}}}\\
\vspace{15mm}
{\Huge{\bf Mechanized, Type-Based}}\\
\vspace{1mm}
{\Huge{\bf Enforcement of Non-Interference}}\\
\vspace{2mm}
{\Huge{\bf in Choreographic Languages}}\\
\end{center}
\vspace{35mm}
\begin{minipage}[t]{0.40\textwidth}
{\Large{\bf Relatore: \\ Saverio Giallorenzo}}\\
\vspace{3mm}\\
{\Large{\bf Correlatore: \\ Marco Peressotti}}
\end{minipage}
\hfill
\begin{minipage}[t]{0.40\textwidth}\raggedleft
{\Large{\bf Presentata da: \\ Marco Bertoni}}
\end{minipage}

\vspace{35mm}
\rule[0.5cm]{15.8cm}{0.6mm}
\begin{center}
{\large{\bf Sessione Ottobre 2025\\}}
{\large{\bf Anno Accademico 2024/2025\\}}
\end{center}
\end{titlepage}
\restoregeometry

\newpage~\newpage

\topmargin=6.5cm
\begin{flushright}
\emph{
\large{The method of `postulating' what we want has many advantages; }\\\vspace{1mm}
\large{they are the same as the advantages of theft over honest toil.}\\\vspace{3mm} 
\large{Russel - 1919} 
}
\end{flushright}

\newpage~\newpage

\pagenumbering{gobble}
\topmargin=-1cm

\tableofcontents
\thispagestyle{empty}

\newpage~\newpage

\pagenumbering{arabic}
\raggedbottom
\chapter{Introduction} \label{chap:intro}
\pagestyle{plain}
\setcounter{page}{1}
Distributed software can be seen as a set of communicating components that jointly implement protocols such as authenticating a user, booking a ticket, or reconciling a payment. At this scale, two concerns have to be considered: \emph{correct coordination} among participants and \emph{confidentiality} of the data they manipulate. \emph{Choreographic languages} address the first concern by describing protocols from a global point of view, from which compliant local behaviours can be derived\cite{montesi2023introduction}. This work tackles the second concern: ensuring, by construction, that a choreography does not leak secret information to public observers.

\paragraph{Motivating example: account recovery without username enumeration}
We illustrate a tiny choreography for password recovery.
We consider the \emph{existence} of an user to be sensitive information, which should not be leaked to the public.
We define three processes: the service \(\mathsf{s}\), the mailer \(\mathsf{m}\) and the  requester \(\mathsf{r}\). Any information observable by the requester is considered public.
The predicate \(\mathsf{exists}(email)\) (which reads: does an account with email \(email\) exist?) returns a \emph{sensitive} datum. We want to be able to differentiate between the two programs in Figure \ref{fig:example}.
In the insecure choreography (left), the requester \(\mathsf{r}\) first sends an email address to the service \(\mathsf{s}\).
Then \(\mathsf{s}\) evaluates the sensitive predicate \(\mathsf{exists}(\mathit{email})\).
If it holds, \(\mathsf{s}\) forwards the address to the mailer \(\mathsf{m}\) and replies to \(\mathsf{r}\) with the literal message \texttt{email sent}; otherwise, it replies with \texttt{unknown user}.
Since we fixed the public observer to be \(\mathsf{r}\), the two executions are distinguishable at \(\mathsf{r}\) by the content of \(\mathsf{s}\!\to\!\mathsf{r}\), so an attacker learns the secret bit \(\mathsf{exists}(\mathit{email})\) from a low observation.
In the safe choreography (right), \(\mathsf{s}\) still branches on \(\mathsf{exists}(\mathit{email})\), but the branch only affects the internal action toward \(\mathsf{m}\) (either send the email or skip); the behavior visible to \(\mathsf{r}\) is uniform, as \(\mathsf{s}\) always replies with \texttt{check your inbox}.
Thus runs that differ only in the secret predicate yield the same low observation at \(\mathsf{r}\), preventing username enumeration and restoring non-interference with respect to the $low$-observer \(\mathsf{r}\).

\begin{figure}[t]
  \centering
  \begin{minipage}[t]{0.48\textwidth}
    \raggedright\textbf{Insecure variant}
    \vspace{0.3em}
\begin{lstlisting}[basicstyle=\ttfamily\small, frame=single, numbers=none]
r.email -> s.email
if s.exists(email) then
    s.email -> m.email
    s."email sent" -> r.msg
else
    s."unknown user" -> r.msg
\end{lstlisting}
  \end{minipage}
  \hfill
  \begin{minipage}[t]{0.48\textwidth}
    \raggedright\textbf{Safe variant}
    \vspace{0.3em}
\begin{lstlisting}[basicstyle=\ttfamily\small, frame=single, numbers=none]
r.email -> s.email
if s.exists(email) then
    s.email -> m.email
else
    skip
s."check your inbox" -> r.msg
\end{lstlisting}
  \end{minipage}

  \caption{Side-by-side comparison of the safe and insecure account recovery choreographies.}
  \label{fig:example}\end{figure}

\medskip
Information flow security offers a principled way to reason about confidentiality.
Following Denning's lattice model of security classes\cite{denning1976lattice}, to every piece of data is assigned a security class ordered by a relation $\sqsubseteq$ over a security lattice $\MCL$.

We focus on a property named \emph{non-interference}\cite{goguen1982security}: intuitively, changes to data at a chosen observation level \(low \in \MCL\) must not affect what an attacker at level \(low\) can observe. In conventional languages, non-interference is often enforced statically by type systems that rule out both \emph{explicit flows} (e.g.\ assigning a secret directly to a public variable) and \emph{implicit flows} (e.g.\ branching on a secret and thereby revealing information through control flow) \cite{volpano1996sound}.

This thesis develops a \emph{mechanized, type-based enforcement of non-interference} for a core choreographic language with procedures, message-passing, selections, assignments, and conditionals. The enforcement is \emph{policy-parametric}: given a user-specified lattice of security classes and an observation level \(low\), the type system rejects any choreography in which high-security data could influence \(low\)-observable behaviour. The typing judgement has the form
\[
  \Delta \;;\; \Gamma \;;\; pc \;\vdash\; C,
\]
where $\Gamma$ assigns security classes to program variables, $pc \in \MCL$ tracks the \emph{current control level}, and $\Delta$ summarizes how procedures may be called safely at different control levels. Typing is compositional on the structure of choreographies.

To obtain these results, two technical devices are key. First, we adopt a standard \emph{program-counter discipline}: the control level $pc$ records the influence of secrets on the current point of execution; once raised (e.g.,\ by branching on a secret), it restricts subsequent low-observable actions until control returns to a lower level. Second, to support modular verification in the presence of recursive procedures, we introduce a \emph{procedure context} $\Delta$ mapping each procedure and control level to a set of admissible variable typings. Intuitively, $\Delta$ captures the summary of how a procedure may be used safely. We show how to \emph{construct} such a $\Delta$ from the procedure definitions by generating and solving constraints, in the spirit of type reconstruction\cite{pierce2002types}.

The enforcement target is a standard, small-step reference semantics for choreographies. Following common practice in the information-flow literature \cite{volpano1996sound}, we consider a \emph{termination-insensitive} attacker: divergence itself is not deemed an observation. To state the main theorem conveniently, we pair the reference semantics with a natural (big-step) judgement that tracks an entire execution. The main result of the thesis is:

\begin{quote}
\emph{Soundness (Termination-Insensitive Non-Interference).} If $\Delta;\Gamma;\bot \vdash C$ and two initial stores are $low$-equivalent w.r.t.\ $\Gamma$, then the $low$-observable outcomes of running $C$ from those stores are indistinguishable to an attacker at level \(low\).
\end{quote}

\noindent
Soundness is proved by a standard \emph{progress and preservation}\cite{pierce2002types} argument tailored to choreographies; well-typedness ensures that:
\begin{itemize}
\item explicit flows respect the policy encoded by $\Gamma$;
\item implicit flows are tracked so that no $low$-observable action depends on high secrets;
\item procedure calls are safe thanks to the invariants captured by $\Delta$.
\end{itemize}

The main theorem is \emph{mechanized} in the Lean proof assistant\cite{de2015lean}, building on an existing Lean formalization of choreographies and standard libraries for order-theoretic structures. Mechanization provides machine-checked assurance that the informal intuitions above are realized precisely.

\paragraph{Contributions.}
Summarizing, the main results of this thesis include:
\begin{itemize}
  \item A \emph{policy-parametric} information-flow type system for choreographies, tracking both data and control via a program-counter discipline and supporting recursion through a procedure context $\Delta$.
  \item A \emph{soundness theorem} stating that well-typed choreographies satisfy termination-insensitive non-interference with respect to the reference semantics.
  \item A \emph{context reconstruction} method that computes $\Delta$ from procedure definitions by constraint generation and solving, together with proofs of its well-formedness properties.
\item A \emph{Lean mechanization} of the language, the type system, and the proofs, integrating with prior formalizations and Mathlib's order-theoretic infrastructure\cite{mathlib4}.
\end{itemize}

\paragraph{Structure of the thesis.}
Chapter \ref{chap:background} introduces choreographies, recalls the essentials of lattice-based information-flow control and non-interference, and summarizes the Lean features used in the mechanization.
Chapter \ref{chap:type-system} presents the language and the type system, motivating each typing rule on representative constructs.
Chapter \ref{chap:soundness-proof} states and proves termination-insensitive non-interference for well-typed programs, using a natural-semantics presentation to express the attacker's observations.
Chapter \ref{chap:delta} develops the construction of the procedure context $\Delta$ and establish its required properties.
Chapter \ref{chap:lean} documents the Lean mechanization, its organization, and the connections to the pen-and-paper development.
The appendices collect auxiliary syntactic lemmas used throughout the proofs.

\chapter{Background} \label{chap:background}
\section{Choreographies}
\label{background:choreographies}
Unless otherwise indicated, all content in this chapter is derived from: \textit{Introduction to Choreographies\cite{montesi2023introduction}} by \textit{Fabrizio Montesi}, updated with the errata corrige present in Montesi's website\cite{montesiChoreographies}.
\vspace{10pt}

Choreographies are formal descriptions of the intended collaborative behavior of processes in concurrent and distributed systems. They act as protocols that specify how different components should interact to achieve a shared goal, such as authenticating a user or completing a purchase online.\\
Although choreographies are written in a different style than traditional local programs, they execute like normal languages: through a sequence of transitions that represent communication and computation steps. However, instead of capturing the state of a single process, a choreography represents the global state of all participants involved, encompassing the joint execution and interactions that collectively implement the protocol.


\subsection{Processes}
The cornerstone of the language will be the notion of \textit{process}. Processes are independent participants in a choreography; they can perform local computation and interact with other processes by communicating with them. From the perspective of computer systems, processes are abstract representations of computer programs executed concurrently; each process possesses its own control state and memory.\\
In this work, processes are usually ranged over by $p, q, r, s, \ldots$ and the infinite set of \textit{process names} will be referred to as \textbf{PName}.

\subsection{Syntax}
We introduce the following language, called \textit{Recursive Choreographies} and defined by the following context-free grammar:
$$
\begin{array}{rcl}
\mathscr{C} & ::= & \{X_i(\vec{p_i}) = C_i\}_{i \in I} \\
C & ::= & I; C \mid \boldsymbol{0} \\
I & ::= & p.e \rightarrow q.x \mid p \rightarrow q[L] \mid p.x := e \mid \text{if } p.e \text{ then } C_1 \text{ else } C_2 \mid X(\vec{p}~) \mid q : X(\vec{p}~).C\\
e & ::= & v \mid x \mid f(\vec{e}~)
\end{array}
$$
Let us explain the grammatical entities introduced:
\begin{itemize}
\item $\mathscr{C}$ denotes the \textit{context of procedure definitions}:\\
	A set of procedure definitions is a (possibly empty) set of equations of the form $X(\vec{p}~) = C$, read \textit{procedure $X$ has parameters $\vec{p}$ and body $C$}, where all procedure names are distinct. We call the parameters $\vec{p}$ of a procedure definition the \textit{formal parameters} of the procedure\footnote{The symbol \( \vec{p} \) refers to the sequence \( p_1, p_2, \dots, p_n \), consisting of the individual components \( p_i \), where \( n \in \mathbb{N} \) is unspecified}.
\item $C$ denotes a \textit{choreography}, which can either be a \textit{terminated choreography} $\boldsymbol{0}$ (the choreography that prescribes no interactions) or the sequential composition of an \textit{instruction} $I$ and a \textit{continuation} $C$\\
We denote with \textbf{Chor} the set of all entities generated by this non-terminal.
\item $I$ denotes an \textit{instruction}, which can be one of the following:
\begin{itemize}
	\item A \emph{communication} $\bm{p.e \rightarrow q.x}$, where process $p$ evaluates the \emph{expression} $e$ locally and communicates the resulting value to process $q$ which stores it in its local variable $x$.
	\item A \emph{selection} $\bm{p \rightarrow q[L]}$.
		Label selections are required for the correct coordination of distributed branching, and solve a problem known as \emph{knowledge of choice}\cite{castagna2012global}. Since the discussion of this problem goes 
beyond the scope of this work, we will just treat it as an arbitrary instruction of the language.
	\item A \emph{local assignment} $\bm{p.x := e}$, where $p$ evaluates expression $e$ and stores the resulting value in its variable $x$.
	\item A \emph{conditional} $\bm{\textbf{if } p.e \textbf{ then } C_1 \textbf{ else } C_2}$, which reads \textit{process $p$ evaluates expression $e$, and then the choreography proceeds as $C_1$ if the result of the evaluation is the value \textit{true}, or as $C_2$ otherwise}. Thus, we now assume that the set of possible values contains the Boolean value \textit{true}. Given a conditional $\bm{\textbf{if } p.e \textbf{ then } C_1 \textbf{ else } C_2}$, $e$ is called the \textit{guard} of the conditional; and the two choreographies $C_1$ and $C_2$ are called the \textit{branches} of the conditional or, more precisely, $C_1$ is the \textit{then-branch} and $C_2$ is the \textit{else-branch}.
	\item A procedure call $\bm{X(\vec{p}~)}$, which reads \textit{run procedure $X$ with the processes $\vec{p}$}. We call the processes $\vec{p}$ the \textit{arguments} of the procedure call.
	\item A run time term $\bm{X(\vec{p}~).C}$,
		The key motivation behind the introduction of run time terms is to correctly represent distributed recursion. They syntactically denote the intermediate states originating from the independent procedure calls executed by the processes participating in the choreography. The discussion of this topic goes beyond the scope of this work, we will just treat run time terms as arbitrary instruction of the language.
\end{itemize}
\item $e$ denotes a \textit{local expression}, which can take three forms:
\begin{itemize}
	\item A \emph{constant value} $v$. We write \textbf{Val} for the set of all possible values.
	\item A \emph{variable} $x$. We write \textbf{Var} for the set of all possible variable names.
	\item A \emph{function call} $f(\vec{e}~)$, where $f$ is a \emph{function name} and $\vec{e}$ are the \emph{arguments} of $f$.
A function name $f$ is a reference to a function that maps value tuples to values. The idea is that these functions can be evaluated locally, in the sense that processes compute their results without communicating with other processes. For this reason, we call functions ranged over by $f$ also \emph{local functions}.
\end{itemize} 
We use \textbf{Expr} for the set of entities generated by $e$
\end{itemize}

\subsection{Semantics}
The interpretation for Choreographies is given as small-step operational semantics\cite{plotkin2004origins}, forming a Labeled Transition System $(S,\textbf{TLabel},\xrightarrow{.})$.\\
$S$ is the configuration space, \textbf{TLabel} represents the set of possible \textit{transition labels} and $\xrightarrow{.}$ represents the \textit{transition relation}.
\subsubsection{Configuration and Choreographic Store}
The configurations have the form $\langle C, \Sigma, \mathscr{C} \rangle$.
$C$ and $\mathscr{C}$ were defined previously in this document.
$\Sigma$ represents the \textit{choreographic store}. Let us now define it.

A \textit{process store} $\sigma$ models the memory of a process, mapping variables to values. Formally, a process store is a function from variables to values:
\[
\sigma : \textbf{Var} \longrightarrow \textbf{Val}.
\]

We write \textbf{PStore} for the set of all process stores. It will often be necessary to update the content of a store, so we define a notation for that purpose. Namely, we write $\sigma[x \mapsto v]$ for the update of store $\sigma$ with the new mapping $x \mapsto v$:
\[
\sigma[y \mapsto v](x) =
\begin{cases}
v & \text{if } x = y \\
\sigma(x) & \text{otherwise}.
\end{cases}
\]

A \textit{choreographic store} (i.e., \textbf{CStore}) $\Sigma$ models the memory state of an entire system: it maps process names to their respective process stores. Formally,
\[
\Sigma : \textbf{PName} \longrightarrow \textbf{PStore}.
\]

We shall write $\Sigma[p.x \mapsto v]$ for the update of store $\Sigma$ such that the local variable $x$ of process $p$ is now mapped to $v$:
\[
\Sigma[q.x \mapsto v](p) =
\begin{cases}
\Sigma(p)[x \mapsto v] & \text{if } p = q \\
\Sigma(p) & \text{otherwise}.
\end{cases}
\]

Store updates are left associative, that is:
\[
\Sigma[p.x \mapsto v][q.y \mapsto u] = (\Sigma[p.x \mapsto v])[q.y \mapsto u].
\]

We adopt extensional equality for both local and choreographic stores: two process stores are deemed equal if they return the same value for each variable, and two choreographic stores are considered equal if they return equal process stores for each process.

\subsubsection{Local Expression Evaluation}
Given a \textbf{PStore} $\sigma$, expression $e$ and value $v$, the notation $\sigma \vdash e \downarrow v$ reads as \textit{$e$ is evaluated to the value $v$ under the process store $\sigma$}. It is defined as the least relation derived by the following inference schema:
\begin{mathpar}
\inferrule{}{ \sigma \vdash v \downarrow v }
\and
\inferrule{}{ \sigma \vdash x \downarrow \sigma(x) }
\and
\inferrule{
  \sigma \vdash e_1 \downarrow v_1 \quad \cdots \quad \sigma \vdash e_n \downarrow v_n
  \quad \vdash f(v_1,\ldots,v_n) \downarrow v
}{
  \sigma \vdash f(e_1,\ldots,e_n) \downarrow v
}
\end{mathpar}
We do not specify a system for deriving propositions of the kind $\vdash f(\vec{v}) \downarrow v$, since it is not
important for our development: this system would depend on how functions are defined, which
we choose to abstract from. Instead, we will just assume that such a system exists, and that for
any $f$ and $\vec{v}$, it is always possible to derive $\vdash f(\vec{v})$ for some $v$.

\subsubsection{Transition Label}
Given two different processes $p, q$, a selection label $L$ and a value $v$, we define \textbf{TLabel} as the set of objects generated by the following grammar:
$$
\textbf{TLabel} ::= \tlint{p} \mid p.v \rightarrow q \mid \gensel \mid \tlthen{p} \mid \tlelse{p}
$$

\subsubsection{Process Names of a Choreography}
Before defining the \textit{transition relation}, we need to define a few auxiliary operators.\\
The first one is the function $\pn$, formalizing the concept of \textit{process names mentioned in an entity}.\\
We overload the $\pn$ name and define two different functions disjoint on their domain, respectively on \textit{choreographies} and \textit{transition labels}.
The one used at any given time will be clear from the argument.
\begin{align*}
	\pn : \textbf{Chor} &\longrightarrow 2^\textbf{PName}\\
	\pn(\boldsymbol{0}) &\triangleq \emptyset\\
    \pn(I; C) &\triangleq \pn(I) \cup \pn(C)\\
    \pn(\gencom) &\triangleq \{p, q\}\\
    \pn(\gensel) &\triangleq \{p, q\}\\
    \pn(p.x \metaDef e) &\triangleq \{p\}\\
	\pn(\text{if } p.e \text{ then } C_1 \text{ else } C_2) &\triangleq \{p\} \cup \pn(C_1) \cup \pn(C_2)\\
    \pn(X(\vec{p}~)) &\triangleq \{\vec{p}~\}\\
    \pn(q : X(\vec{p}~).C ) &\triangleq \{q\}\\
\end{align*}
\begin{align*}
	\pn : \textbf{TLabel} &\longrightarrow 2^\textbf{PName}\\
	\pn(\tlint{p}) &\triangleq \{ p \}\\
    \pn(p.v \rightarrow q) &\triangleq \{p , q\}\\
    \pn(\gensel) &\triangleq \{p , q\}\\
    \pn(\tlthen{p}) &\triangleq \{ p \}\\
    \pn(\tlelse{p}) &\triangleq \{ p \}\\
\end{align*}

\subsubsection{Sequential Composition Operator}
The operator is defined as follows, both on \textit{choreographies} and \textit{instructions}:
\begin{align*}
	\boldsymbol{0} \fatsemi C &= C\\
    (I; C') \fatsemi C &= (I \fatsemi C); (C' \fatsemi C)\\
    I \fatsemi C &= 
    \begin{cases}
		q : X(\vec{p}~).(C' \fatsemi C) &\text{if $I = q : X(\vec{p}~).C' $}\\
		I &\text{otherwise}
    \end{cases}
\end{align*}

\subsubsection{Process substitution}
\label{intro:chor_subst}
The name substitution of a process $p$ is defined as:
\begin{align*}
    p[r/s] \triangleq
    \begin{cases}
    &s \quad \text{if $p = r$}\\
    &p \quad \text{otherwise}
    \end{cases}
\end{align*}
We can now define the name substitution for \textit{choreographies}:
\begin{align*}
	\boldsymbol{0}[r/s] &\triangleq \boldsymbol{0}\\
    (I; C)[r/s] &\triangleq (I[r/s]); (C[r/s])\\
    (\gencom)[r/s] &\triangleq (p[r/s].e) \rightarrow (q[r/s]).x\\
    (\gensel)[r/s] &\triangleq (p[r/s]) \rightarrow (q[r/s])[L]\\
    (p.x \metaDef e)[r/s] &\triangleq (p[r/s]).x \metaDef e\\
    (\text{if } p.e\text{ then } C_1\text{ else } C_2) &\triangleq \text{if }(p[r/s]).e \text{ then }(C_1[r/s]) \text{ else } (C_2[r/s])\\
    (X(\vec{p}~)[r/s]) &\triangleq X(\vec{p}~[r/s])\\
	(q : X(\vec{p}~).C) [r/s] &\triangleq q[r/s] : X(\vec{p}~[r/s]).(C[r/s])\\
\end{align*}


\subsubsection{Transition Relation}
At this point we have all the necessary machinery to define the \textit{transition relation} $\xrightarrow{.}$ as the smallest relation derived by the following inference schemata:
$$
    \inferrule*[right=local] { \Sigma(p) \vdash e \downarrow v }
    {\langle p.x \metaDef e ; C, \Sigma, \mathscr{C} \rangle \xrightarrow{\tlint{p}} \langle C, \Sigma[p.x \mapsto v], \mathscr{C} \rangle}
$$ $$
    \inferrule*[right=com] { \Sigma(p) \vdash e \downarrow v } 
    {\langle \gencom ; C, \Sigma, \mathscr{C} \rangle \xrightarrow{p.v \rightarrow q} \langle C, \Sigma[q.x \mapsto v], \mathscr{C} \rangle}
$$ $$
    \inferrule*[right=sel] {  } 
    {\langle \gensel ; C, \Sigma, \mathscr{C} \rangle \xrightarrow{\gensel} \langle C, \Sigma, \mathscr{C} \rangle}
$$ $$
    \inferrule*[right=cond-then] { \Sigma(p) \vdash e \downarrow \mathit{true}} 
    {\langle \text{if } p.e\text{ then } C_1\text{ else } C_2 ; C, \Sigma, \mathscr{C} \rangle \xrightarrow{\tlthen{p}} \langle C_1 \fatsemi C, \Sigma, \mathscr{C} \rangle }
$$ $$
    \inferrule*[right=cond-else] { \Sigma(p) \vdash e \downarrow v \\ v \neq \mathit{true}} 
    {\langle \text{if } p.e\text{ then } C_1\text{ else } C_2 ; C, \Sigma, \mathscr{C} \rangle \xrightarrow{\tlelse{p}} \langle C_2 \fatsemi C, \Sigma, \mathscr{C} \rangle }
$$
\makebox[\textwidth][c]{\resizebox{1.2 \textwidth}{!}{$
    \inferrule*[right=call-first] { X(\vec{q}~) = C \in \mathscr{C} \\ \vec{p} = p_1, \ldots, p_n \\ i \in [1,n] }
	{\langle X(\vec{p}~);C', \Sigma, \mathscr{C} \rangle \xrightarrow{\tlint{p_i}} \langle p_1 : X(\vec{p}~).C'; \ldots; p_{i-1} : X(\vec{p}~).C'; p_{i+1} : X(\vec{p}~).C'; \ldots; p_n : X(\vec{p}~).C'; C[\vec{q}/\vec{p}~] \fatsemi C', \Sigma, \mathscr{C} \rangle}
$}} $$
    \inferrule*[right=call-enter] {  }
	{\langle q : X(\vec{p}~).C'; C, \Sigma, \mathscr{C} \rangle \xrightarrow{\tlint{q}} \langle C, \Sigma, \mathscr{C} \rangle}
$$ $$
    \inferrule*[right=delay] {\langle C, \Sigma, \mathscr{C}\rangle \xrightarrow{\mu} \langle C', \Sigma', \mathscr{C}\rangle \\ \pn(I)\cap\pn(\mu) = \emptyset} 
    {\langle I; C, \Sigma, \mathscr{C}\rangle \xrightarrow{\mu} \langle I; C', \Sigma', \mathscr{C}\rangle}
$$ $$
    \inferrule*[right=delay-cond] {\langle C_1, \Sigma, \mathscr{C}\rangle \xrightarrow{\mu} \langle C_1', \Sigma', \mathscr{C}\rangle \\ \langle C_2, \Sigma, \mathscr{C}\rangle \xrightarrow{\mu} \langle C_2', \Sigma', \mathscr{C}\rangle \\ p\notin \pn(\mu)}
    {\langle \text{if } p.e\text{ then } C_1\text{ else } C_2 ; C, \Sigma, \mathscr{C} \rangle \xrightarrow{\mu} \langle \text{if } p.e\text{ then } C_1'\text{ else } C_2' ; C, \Sigma', \mathscr{C} \rangle}
$$
Let us now say a few words about these rules:
\begin{itemize}
\item LOCAL, COM, COND-THEN, COND-ELSE need no explanation.
\item Rule CALL-FIRST, CALL-ENTER deal with running a procedure. The motivation behind the seemingly complicated rules goes beyond the scope of this work and can be found in Montesi's book\cite{montesi2023introduction}. The main intuition is the following: processes are independent and can \emph{enter} the procedure at any interleaved order, but we need some syntactical marker in the choreography to correctly coordinate distributed recursion. 
	What needs to be noted is that the rule CALL-FIRST looks up the procedure definition from the context, performs \textit{processes substitutions} to replace the \textit{formal parameters} with the \textit{arguments} and inserts it into the continuation of the running choreography. The rule CALL-ENTER removes one by one the \textit{runtime terms} introduced by CALL-FIRST.
\item Rule DELAY captures in choreographies the notion that processes are independent of each other.
\item Rule DELAY-COND, models the concurrent execution of instructions that are independent of a conditional, thus complementing DELAY.
\end{itemize}

\paragraph{Multi-step transitions}
For notational ease, we define $\cdot \twoheadrightarrow \cdot$ as the transitive, reflexive closure of $\cdot \xrightarrow{.} \cdot$.

\subsection{Notes on expressivity}
The presented language can be shown to be Turing Complete\cite{cruz2020core}.
For Turing-complete languages, any \emph{nontrivial} \emph{extensional} (i.e., semantic) property of programs is undecidable\cite{rice1953classes}. If a property depends only on the function computed by a program and holds for some but not all computable functions, then there is no algorithm that always decides whether an arbitrary program has that property.
The property we will consider in the main contribution of this work and which will be introduced in the next chapter is semantic in this sense, so no complete decision procedure exists in general.

\subsection{Notes on small-step semantics}
Because big‑step semantics collapses the entire execution into a single relation between initial and final states, it inherently lacks the granularity required to represent instruction-level reordering. Consequently, it is inapplicable to model out‑of‑order execution: a feature that fundamentally relies on the scheduling and interleaving of micro-steps.

\section{Information flow analysis}
In modern computing systems, the handling and protection of data is of critical importance\cite{iso27001_2022}. With the proliferation of interconnected systems, sensitive data such as personal information, financial records, and classified communications is constantly processed, transmitted, and stored\cite{zhang2022data}. Ensuring that this information is handled securely and does not unintentionally or maliciously flow to unauthorized entities is a major challenge in computer science and software engineering\cite{zhang2022data}. Information Flow Analysis\cite{denning1976lattice} is a set of techniques aimed at analyzing how information propagates through a program or system, with the goal of identifying potential leaks or violations of security policies.

In Denning's formulation\cite{denning1976lattice}, secure information flow means that all data transfers conform to a \textit{flow policy} defined by a relation \( \rightarrow \), where \( A \rightarrow B \) indicates that information is permitted to flow from \textit{security class} \( A \) to \textit{security class} \( B \).
\textit{Security classes} correspond to disjoint classes of information. They are intended to encompass \textit{security classifications}. Each object in the system is bound to a security class.

Information flows can arise in two principal ways:
\begin{itemize}
  \item \textbf{Explicit flows} occur when operations like assignment or message passing directly transfer information from one location to another.
  \item \textbf{Implicit flows} occur when the control structure of the program (e.g., conditionals or loops) induces a dependency between variables, such that the value of one variable may be inferred from the control decisions influenced by another, without any explicit data transfer. For example:
\begin{lstlisting}[caption={Example of implicit flow}, label={lst:implicit_flow}]
public = 1
if secret == 0:
    public = 0
\end{lstlisting}
This code creates an implicit flow from \texttt{secret} to \texttt{public}, even though \texttt{public} is not explicitly assigned from \texttt{secret}.
\end{itemize}
Secure flow analysis of any system must capture both types of flows to ensure that all data transfers respect the flow relation.

A central result of Denning’s work is the recognition of a \textit{lattice structure} over the flow relation. The lattice ensures that:
\begin{itemize}
  \item Every pair of classes has a unique \textit{least upper bound} (join \( \sqcup \)) and \textit{greatest lower bound} (meet \( \sqcap \)).
If a value computed from multiple sources is assigned to a target, then the \textit{composite class} of the sources (computed using the \textit{least upper bound} operator) must be allowed to flow into the class of the target.
  \item Security of individual operations implies the security of sequences of operations, by transitivity of $\rightarrow$.
\end{itemize}

Information Flow Analysis can be conducted using:
\begin{itemize}
  \item \textbf{Static analysis}, which inspects code without executing it to verify that all potential flows are secure.
  \item \textbf{Dynamic analysis}, which tracks actual flows during execution by tagging and monitoring data.
  \item \textbf{Hybrid approaches}, which use static guarantees and insert run time checks where necessary.
\end{itemize}

Denning's \textit{Information Flow Analysis} provides a formal framework for reasoning about how data propagates through programs, enabling the development of tools and techniques that can be evaluated against a mathematically grounded, lattice-based policy structure.

\paragraph{Is information-flow control enough?}
Information-flow analysis, as usually formulated at the language level, reasons
about flows that are explicit in values and implicit in control flow according to
the operational semantics\cite{sabelfeld2003language}.
\emph{Side channels} (e.g., timing, termination,
resource usage, cache effects, message sizes, or scheduler-dependent behavior)\cite{kelsey1998side}
fall outside this view, unless the semantics and the attacker observation model
explicitly make them observable.
Any security guarantee should therefore be read
\emph{relative to the chosen observation model}.
When side channels matter, they can be brought into scope by enriching the semantics with cost or timing
observables and adopting timing-/step-sensitive definitions\cite{197207}.

\section{Non-Interference}
\label{background:noninterference}
Denning's work\cite{denning1976lattice} is primarily concerned with the design and specification of information flow policies rather than their enforcement in concrete programming languages. Notably, the lattice model does not define how to formally relate a program's execution semantics to the flow policy. While the model is sound as a representation of policy, it operates at an abstract level, and leaves open the question of how to \textit{rigorously} ensure that actual programs respect the intended information flow restrictions.\footnote{In the concluding section of her paper, Denning briefly surveys various enforcement mechanisms, including compiler-based techniques and hardware support. However, this survey is based on intuitive arguments rather than being a formal account.}

The notion of non-interference\cite{goguen1982security} provides a semantic formalization that addresses this limitation. Informally, non-interference requires that variations in high-security (confidential) inputs must not influence low-security (observable) outputs\cite{volpano1996sound}. This condition captures the intuitive idea that secret data should not interfere with what an external observer can learn from the behavior of a program. Importantly, non-interference can be defined with respect to the program's operational semantics, thereby allowing for formal soundness proofs of enforcement mechanisms that guarantee compliance with the security policy\cite{volpano1996sound}.

In contrast, purely dynamic enforcement mechanisms such as run time monitors are unable to detect certain classes of implicit information leaks\cite{sabelfeld2003language}.
Let us look back at the example code in \ref{lst:implicit_flow}.
Dynamic mechanisms typically monitor only the path that is actually taken during execution. If this program is executed with $\verb|secret| \ne 0$, the conditional branch is skipped and no assignment to \verb|public| occurs. A dynamic monitor observing this trace would see no operation involving \verb|public|, and thus incorrectly conclude that no illegal information flow has occurred\footnote{Unless monotonically increasing \emph{label creep}\cite{sabelfeld2003language} is accepted as result of the analysis.}. An attacker observing the final value of \verb|public| still gains information: \verb|public|, having value 1, implies that the condition \verb|secret == 0| did not hold. That is, the attacker can rule out one possible value for \verb|secret|. While the leaked information may appear small, it is nonetheless a violation of confidentiality.

This illustrates a fundamental shortcoming: dynamic enforcement cannot reason about \textit{potential} flows along branches not taken. Since information flow security is a property of all possible executions\cite{sabelfeld2003language}\cite{denning1976lattice}, such mechanisms are inherently incomplete in capturing the full security implications of a program.
In contrast, static approaches can be equipped to reason about all program paths\cite{volpano1996sound} and thus offer a more precise and rigorous framework for enforcing confidentiality.

\subsection{Definition}
Let us consider a simple imperative programming language\cite{winskel1993formal} with commands such as assignments, sequencing, conditionals, and loops. A program state $s$ is typically modeled as a mapping from variables to values\cite{winskel1993formal}, that we will partition into \emph{high} and \emph{low} components: $s = \langle s^h, s^l \rangle$, where $s^h$ contains high-security data and $s^l$ contains low-security data.

The semantics of a program $C$ is given\cite{kahn1987natural}\cite{nielson1992semantics} by a function $\llbracket C \rrbracket : S \rightarrow S_\perp$, where $S$ is the set of program states and $S_\perp = S\ \cup \{ \perp \}$ includes a special element $\perp$ representing non-termination.

Let $s_1 \equiv_L s_2$ denote that two states are \emph{low-equivalent} i.e., they agree on all low-security variables: $s_1^l = s_2^l$.

Then, the formal definition of non-interference is\cite{volpano1996sound}\cite{goguen1982security}, for all $s_1, s_2 \in S$:
\[
  s_1 \equiv_L s_2 \Rightarrow \llbracket C \rrbracket(s_1) \approx_L \llbracket C \rrbracket(s_2)
\]
Here, \(\approx_L\) denotes \emph{observational equivalence}\footnote{This notion of observational equivalence can be naturally extended to account for additional observables beyond final low-security state and termination behavior\cite{sabelfeld2003language}. For instance, one may define \(\approx_L\) to reflect distinctions based on execution time (capturing timing channels), on the sequence of outputs to public channels (capturing event traces), or on probabilistic distributions over outputs (capturing probabilistic leakage).} from the perspective of a low-security observer. In a termination sensitive setting\cite{hedin2012perspective}, this relation is defined as follows:
\begin{equation}
\llbracket C \rrbracket(s_1) \approx_L \llbracket C \rrbracket(s_2)
\quad\text{iff}\quad
\begin{cases}
\llbracket C \rrbracket(s_1) =\ \perp \ \text{and}\ \llbracket C \rrbracket(s_2) =\ \perp, \\
\text{or} \\
\llbracket C \rrbracket(s_1), \llbracket C \rrbracket(s_2) \in S \ \text{and}\
\llbracket C \rrbracket(s_1) \equiv_L \llbracket C \rrbracket(s_2)
\end{cases}
\label{eq:approx_tsni}
\end{equation}


This definition ensures that, for any two initial states that agree on low-security data, their respective executions are indistinguishable to an attacker who observes only low-security outputs and can detect (non-)termination.

\subsubsection{Termination Sensitivity}
When formalizing non-interference, a key consideration is whether termination behavior should be treated as an observable effect\cite{hedin2012perspective}. This leads to two distinct variants of the property: \emph{termination sensitive non-interference} and \emph{termination insensitive non-interference}.

\paragraph{Termination-sensitive non-interference} requires that secret inputs cannot affect \emph{either} the final low-observable state \emph{or} whether the program terminates\cite{volpano1997eliminating}. Formally, in this setting, the observational equivalence relation $\approx_L$ is defined as shown in \ref{eq:approx_tsni}. To illustrate why termination sensitive non-interference may be preferable, consider the following program:
\begin{lstlisting}[language=Python]
if secret == 0:
    while True: pass
\end{lstlisting}
In this example, the secret variable influences whether the program terminates. Specifically, if \lstinline|secret| is zero, the program diverges, otherwise it terminates immediately. Thus, an attacker who observes termination behavior can directly infer the value of \lstinline|secret|, revealing confidential information through the program's termination. This scenario provides a strong rationale for adopting termination sensitive non-interference in settings where termination or responsiveness is observable.

\paragraph{Termination-insensitive non-interference} by contrast, assumes that non-ter\-mi\-na\-tion is \emph{not} observable by the attacker\cite{goguen1982security}. 
Under this weaker definition, the observational equivalence relation $\approx_L$ only requires that whenever two executions terminate, they yield indistinguishable low-observable states\cite{volpano1996sound}:
\[
\llbracket C \rrbracket(s_1) \approx_L \llbracket C \rrbracket(s_2)
\quad\text{iff}\quad
\llbracket C \rrbracket(s_1), \llbracket C \rrbracket(s_2) \in S \implies
\llbracket C \rrbracket(s_1) \equiv_L \llbracket C \rrbracket(s_2)
\]
In this setting, divergences influenced by secret data are allowed.

The choice between these two definitions ultimately depends on the attacker model assumed. Termination-sensitive non-interference provides stronger guarantees and is well-suited for high-assurance scenarios in which termination behavior is observable by the attacker.
Termination-insensitive non-interference is weaker but simplifies analysis and enforcement by eliminating the need to handle issues related to termination or infinite loops, which is particularly important because non-interference cannot be enforced in a sound and precise manner in the presence of these behaviors\cite{ngo2018impossibility}.

\section{Lean Proof Assistant}
\label{background:proofassistants}

A \emph{proof assistant} is an interactive system for developing machine-checked mathematics.
Mechanized proofs\footnote{In this thesis, ``mechanized'' means that all the stated theorems have corresponding Lean artifacts that type-check.} provide stronger assurance by forcing full formalization and having a small trusted checker verify every inference, catching subtle gaps and mistakes that pen-and-paper often miss. They also yield reproducible, maintainable, and scalable artifacts (proof scripts) that anyone can re-run, audit, and extend with automation, making it feasible to verify large, evolving systems\cite{harrison2014history}.
These guarantees are particularly useful for meta-theoretic results about programming languages, where small omissions (e.g.\ missing cases in an induction) are common and subtle\cite{aydemir2005mechanized}.

\subsection{Underlying theory}
Lean is based on a version of dependent type theory known as the Calculus of Constructions\cite{coquand1986calculus} (\emph{i.e.} CoC), with a countable hierarchy of non-cumulative universes and inductive types\cite{avigad2021theorem}. Dependent type theory is a powerful and expressive language allowing you to express complex mathematical assertions.\\
Lean employs a cumulative hierarchy $Type_0 \subset Type_1 \subset \cdots$ (universe polymorphism) to avoid paradoxes while retaining expressivity\cite{martin1984intuitionistic}.
Inductive types are the general well-founded tree types (initial algebras of polynomial functors) that subsume familiar datatypes like naturals, lists, and trees and justify their structural recursion and induction principles\cite{martin1984intuitionistic}.

Under the Curry-Howard correspondence, propositions are types and proofs are programs inhabiting those types\cite{howard1980formulae}.
Using the Lean programming language we are able to write proof-terms that inhabit arbitrary propositions, expressed in CoC, by type-checking. An inhabited proposition is considered as true. This view of the Curry-Howard correspondence gives us \emph{proof irrelevance}, that is, two proof-terms are considered equal if they construct the same type.

Proofs are usually written by the user in an higher-level, \emph{tactics} language and then compiled to proof-terms. 
As we said, we can view a term as a representation of a construction or mathematical proof; \emph{tactics} are commands, or instructions, that describe how to build such a term.
Soundness of the proof system ultimately rests on a small \emph{trusted kernel}: a compact type-checker that implements Lean's dependent type theory and accepts only well-typed proof-terms\cite{de2015lean}.

\subsection{Lean features used in project}
\paragraph{Pattern matching, recursion, and mutuality.}
Lean supports structural recursion and induction; when definitions depend on each other (e.g.\ instructions and choreographies), we use \emph{mutual} recursion/induction.
This mirrors the mutual inductive structure of the language and will reappear whenever we prove properties by simultaneous induction on related syntactic categories.

\paragraph{Type classes and algebraic structure.}
Algebraic structure (orders, joins, bottom) is provided via \emph{type classes}.
For the security lattice described in \ref{background:noninterference} we rely on instances such as partial orders and lattice with a least element~\((\bot)\).
Type-class resolution lets us write generic lemmas that work for any instance of these interfaces (e.g.\ monotonicity of joins, distributivity properties actually used in typing).

\paragraph{Finite collections and decidability.}
We use \texttt{Finset} to represent finite sets (e.g.\ sets of process names).
Membership and set operations are computable; many lemmas require decidable equality on elements.
This setup simplifies counting arguments, case splits over finite supports, and proofs that manipulate environments whose keys form finite domains.

\paragraph{Proof automation.} In Lean, \texttt{simp} is the simplifier tactic: it repeatedly rewrites goals and hypotheses using a curated set of rewrite lemmas. It is best used to normalize terms and discharge straightforward equalities and propositional reasoning. Moreover, \texttt{aesop} is a general-purpose proof search tactic that explores introduction/elimination rules, constructors, and user-declared rules in a goal-directed, saturation-style search\cite{limperg2023aesop}. Both are extensible, so registering domain-specific lemmas/rules can make common arguments essentially automatic.

\chapter{Enforcement of the Non-Interference Property in Choreographies}
\label{chap:type-system}
The main contribution of this thesis is the development of a mechanism to check the compliance of a choreography against an user specified flow policy.
As argued previously, it is advantageous to develop this system statically.
A static type-system, defined as a type judgment relation, is the natural vehicle to enforce non-interference in choreographies because it turns a semantic security requirement into a syntactic discipline that can be checked algorithmically, integrated into compilation, and compositional on the inductive structure of the program.
Volpano, Smith, and Irvine\cite{volpano1996sound} established the standard soundness connection between such typing judgments and non-interference, providing a proof-theoretic route to a semantic guarantee. In this context, \textit{soundness} is defined as follows.
A type-system is considered sound if, for any flow policy $\Pi$, every program that is well-typed under $\Pi$ is \textit{semantically compliant} with $\Pi$; that is, it satisfies termination insensitive non-interference.

The following work is greatly inspired by previous standard techniques for defining and proving soundness of type judgments \cite{myers2011proving}\cite{wright1994syntactic}, applied to the case of the \emph{choreographic language} defined in the previous chapter.

\paragraph{Roadmap.}
The remainder of this chapter is organized as follows: Section~\ref{type:flow-policy} formalizes the flow policy as a security lattice; Section~\ref{type:intuitive} develops the main intuitions that motivate the type system; and Section~\ref{type:formal} presents the formal definition of the type system.

\section{Definition of the flow-policy}
\label{type:flow-policy}
\textit{Security labels} are elements of a complete lattice $(\mathscr{L}, \sqsubseteq)$ endowed with a bottom element $\bot$ such that every $l \in \mathscr{L}$ respects $\bot \sqsubseteq l$.
These labels capture Denning's notion of security classes where every object manipulated by the program has an associated security class. We implement this by assigning a security label to every variable of the program.

A \textit{process security labeling} $\gamma$ models the security class \textit{i.e., security label} associated with the variables accessed by a process. Formally, a process labeling is a function from variables to security labels:
\[
	\gamma : \textbf{Var} \longrightarrow \mathscr{L}
\]

We write \textbf{SecPLab} for the set of all process security labelings.
Similarly to what we defined for \textit{choreographic stores}, we define a \textit{choreographic security labeling} $\Gamma$ as a map from process names to their respective process labeling. Formally,
\[
\Gamma : \textbf{PName} \longrightarrow \textbf{SecPLab}.
\]
We write \textbf{SecCLab} for the set of all choreographic security labelings.

In the non-interference framework, the flow-policy is fully specified by the security labeling: we forbid any flow of information from an object (in this case, variable) with an \textit{higher} security associated label towards an object with a \textit{lower} associated label.\footnote{The notion of higher and lower are defined naturally from the partial order relation $\sqsubseteq$.}

\section{Intuitive presentation of the type-system}
\label{type:intuitive}
\subsection{A motivating example for Program Counter labeling}
As we saw, to ensure non-interference, we need to consider both \textit{implicit} and \textit{explicit} flows.
Let us see some examples and build the intuition behind the type-system.
\begin{itemize}
	\item{\textbf{Explicit flows}}: Let us try to build a type-system \textit{only} concerned with verifying explicit flows, trying to verify the following choreography:
$$ p.x := y + z; ~ p.x \rightarrow q.x; ~ \boldsymbol{0} $$
	The system can be built by composing constraints on the security labels of the variables, more precisely this program would follow the flow-policy $\Gamma$ if:
	\begin{align*}
		\Gamma~p.y ~\sqcup~ \Gamma~p.z &\sqsubseteq \Gamma~p.x\\
		\Gamma~p.y &\sqsubseteq \Gamma~q.x
	\end{align*}
	\item{\textbf{Implicit flows}}: Now, building from the previous example, let us introduce an implicit flow of information:
	$$ \text{if } p.(a == 0) \text{ then } p.x := 0; ~ \boldsymbol{0} \text{ else } p.x := y + z; ~ \boldsymbol{0}; ~ p.x \rightarrow q.x; ~ \boldsymbol{0} $$
	We need to consider a further element: \textit{the security label of the execution context}. In this particular case, the security label of the context depends on the security label of $p.a$. We can, thus, update our constraints to:
	\begin{align*}
		\Gamma~p.y~\sqcup~\Gamma~p.z~\sqcup~\Gamma~p.a &\sqsubseteq \Gamma~p.x\\
		\Gamma~p.y &\sqsubseteq \Gamma~q.x
	\end{align*}
	We model this by keeping track of $pc \in \mathscr{L}$ in the \textit{assumption} of the type judgment.
\end{itemize}

\subsection{Typing procedure calls}
Most of the foundational work on non-interference\cite{sabelfeld2003language} builds type-systems for a \textit{while language}, but we find ourselves having to develop one for a language supporting recursive procedures.

For this goal, we introduce a \textit{procedure security context} \textbf{SecFunCtx}
$$\Delta: \textbf{ProcName} \times \MCL \rightarrow 2^\textbf{SecCLab}$$
such that, for every $X, pc$ such that $\Gamma ~ \in ~ \Delta ~ X ~ pc$, then the body of $X$ is \textit{well typed} under $\Gamma \text{ and } pc$.

Further discussion on how to compute the context which carries this property will follow in Chapter \ref{chap:delta}, as of now its existence will simply be assumed.

\subsection{Putting it all together}
We are now ready to define our type judgment relation:
\begin{itemize}
  \item Local expressions are assigned a security label by taking the supremum of the security labels of the occurring variables
  \item Instructions that modify the store (assign, send) use the check discussed previously (considering also the value of $pc$), so explicit and implicit flows are handled uniformly.
  \item Conditionals lift $pc$ with the guard's security label on both branches, preventing leaks through control flow.
  \item Calls are verified against $\Delta$, which lets us reason about recursion without unrolling.
  \item Choreographies compose by conjunction: sequencing preserves well-typing if each component does.
\end{itemize}

\section{Formal definition of the Type System}
\label{type:formal}

\subsection{Judgment relation}
We use three typing judgments, one for every syntactic category used to define choreographies. We will overload the $\vdash$ symbol. The relation used will be clear by the context. The three relations are denoted as follows:
\begin{itemize}
	\item{\textbf{Expressions}} \(\Gamma~p \vdash e : \ell\)
	\item{\textbf{Instructions}} \(\Delta;\Gamma;pc \vdash I\)
	\item{\textbf{Choreographies}} \(\Delta;\Gamma;pc \vdash C\)
\end{itemize}
Where $\ell \in \MCL$ 

\subsection{Typing Rules for Expressions}\label{typ_def:expr}
Expressions are always considered local and every local function is considered \textit{deterministic} and \textit{total}. Thus we define
$$ \cdot ~\vdash~ \cdot~:~\cdot ~~~:~~~ \textbf{SecPLab} \rightarrow \textbf{Expr} \rightarrow \MCL $$
As the smallest relation following the following inference schema:

\medskip
\noindent\textbf{Constant}
\[
  \inferrule{}
  {\gamma \vdash v : \bot}
\]

\medskip
\noindent\textbf{Variable}
\[
  \inferrule{}
  {\gamma \vdash x : \gamma~x}
\]

\medskip
\noindent\textbf{N-ary function}
\[
\inferrule{
  \gamma\vdash e_1:\ell_1 \;\; \cdots \;\; \gamma\vdash e_n:\ell_n\\
  \ell' = \sqcup_{i=1}^{n} \ell_i
}{
  \gamma\vdash f(e_1,\dots,e_n):\ell'
}
\]
We assume primitive functions to be label-preserving and to not introduce any extra leak of information.
The typing rule thus assumes that functions do not introduce additional sensitivity; the result is at least as sensitive as the arguments.

\subsection{Typing Rules for Instructions}
\medskip
\noindent\textbf{Assignment}
\[
  \inferrule
  {\Gamma~p \vdash e : \ell' \quad \ell' \sqcup pc \;\sqsubseteq\; \Gamma~p~x}
  {\Delta;\Gamma;pc \vdash \; p.x := e}
\]

\medskip
\noindent\textbf{Communication}
\[
  \inferrule
  {\Gamma~p \vdash e : \ell' \quad \ell' \sqcup pc \;\sqsubseteq\; \Gamma~q~x}
  {\Delta;\Gamma;pc \vdash \; p.e \to q.x}
\]
We can see how communication is treated as an assignment between processes. This requires as assumption that \textit{communication channels are private}, i.e., no other party outside of sender and receiver can read the content of the channel.

\medskip
\noindent\textbf{Selection and Runtime Call Term}
\[
	\inferrule{}{
	\Delta;\Gamma;pc \vdash \; p \to q[\mathsf{L}]
    \quad\text{ and }\quad
    \Delta;\Gamma;pc \vdash \; X(\vec{p}~).C
  }
\]
Both terms are administrative, carry no data, and do not influence information-flow. We consider them as always well-typed.

\medskip
\noindent\textbf{Conditionals}
\[
  \inferrule
  { \Gamma~p \vdash e : \ell'
    \quad
    \Delta;\Gamma;\,\ell' \sqcup pc \vdash C_1
    \quad
    \Delta;\Gamma;\,\ell' \sqcup pc \vdash C_2 }
  {\Delta;\Gamma;pc \vdash \; \mathbf{if}\;p.e\;\mathbf{then}\;C_1\;\mathbf{else}\;C_2}
\]

\medskip
\noindent\textbf{Procedure Calls}
\[
  \inferrule
  { \Gamma' \in \Delta(X,pc) 
    \quad
    \Gamma[\vec{q}\mapsto \vec{p}] \equiv_{\{\vec{q}\}} \Gamma' }
  { \Delta;\Gamma;pc \vdash \; X(\vec{p})}
\]
Where $\vec{q}$ is the list of formal parameters of the procedure $X$ in the context, and $\vec{p}$ is the list of arguments applied to the procedure call.\\
Let us unpack the meaning of this rule.
As we know from the definition of $\Delta$, $\Gamma'$ will be a security context that well-types the body of $X$.
Let us now focus on the second antecedent of the rule by defining two new operators.
\paragraph{Context renaming}
Given lists of processes $\vec{q} = q_1,\dots,q_n$ and $\vec{p} = p_1,\dots,p_n$ (always considered of equal length), we write
$\Gamma[\vec{q}\mapsto \vec{p}]$
for the environment obtained from $\Gamma$ by updating the context pointed by each $p_i$ to mirror the one pointed by $q_i$. Formally (in the scalar case):
\begin{align}
\begin{split}\label{def:context_renaming}
	\Gamma[q \mapsto p]~r \triangleq
    \begin{cases}
    &\Gamma~p \quad \text{if $q = r$}\\
    &\Gamma~r \quad \text{otherwise}
    \end{cases}
\end{split}
\end{align}
\paragraph{Restricted equality}
For a finite set of processes $S$, write $\Gamma \equiv_S \Gamma'$ when $\Gamma$ and $\Gamma'$ agree on all variables of all processes in $S$. Formally, considering extensional equality between maps:
$$ \Gamma \equiv_S \Gamma' ~~~\triangleq~~~ \forall r \in S,~~~\Gamma~r = \Gamma'~r$$

Given these two definitions, we can explain the meaning of the second antecedent as follows. For every process $q_i$ in the formal parameters, then $\Gamma'~q_i$ is the same as $\Gamma~p_i$, with $p_i$ as the process in the arguments corresponding to $q_i$. \footnote{The rule could be less strict: we could only consider single variables restriction instead of process-level equality. The choice of using process equality was made to not over-complicate the definitions and the proof to follow.}

\subsection{Typing Rules for Choreographies}
The type-system composes on the instructions making up a choreography.

\medskip
\noindent\textbf{Sequencing}
\[
  \inferrule
  { \Delta;\Gamma;pc \vdash I \quad \Delta;\Gamma;pc \vdash C }
  { \Delta;\Gamma;pc \vdash \; I \,;\, C }
\]

\medskip
\noindent\textbf{Empty Choreography}
\[
  \inferrule
  {}{\Delta;\Gamma;pc \vdash \; \boldsymbol{0}}
\]

\chapter{Soundness of the Type System}
\label{chap:soundness-proof}
For the type-system to be interesting, we need to prove its soundness with respect to termination insensitive non-interference against the reference semantics.

\section{Overall Statement and Proof Obligations}

Fix a public observation level \(low \in \MCL\).
Recall that \( \llbracket C \rrbracket : S \to S_\perp \) is the (partial) denotational semantics of choreographies into states \(S\) extended with \(\perp\) (non-termination), that \(s_1 \equiv^\Gamma_{low} s_2\) means the two states agree on all variables labeled \(\sqsubseteq low\) in $\Gamma$.

The soundness theorem states that \emph{well-typed programs satisfy termination insensitive non-interference}:
\[
  \Delta;\Gamma;\bot \vdash C
  \quad\Longrightarrow\quad
  \forall s_1,s_2 \in S.\ s_1 \equiv^\Gamma_{low} s_2 \ \Rightarrow\ \llbracket C \rrbracket(s_1) \approx_? \llbracket C \rrbracket(s_2).
\]
To fully specify this theorem, we need to define an equivalence relation that encodes the concept of \emph{low-equivalence under termination insensitive non-interference}.
To join this need with the semantics presented in \ref{background:choreographies}, we introduce a \emph{natural semantics}\cite{kahn1987natural} for choreographies. We define a relation:
\begin{equation}\label{nat_sem}
\langle C, \Sigma, \mathscr{C} \rangle \Downarrow^M \Sigma'
\end{equation}
Where:
\begin{itemize}
	\item $C \in \textbf{Chor}$: Choreography
	\item $\Sigma, \Sigma' \in S$: Choreographic store
	\item $\mathscr{C}$: Procedure context
	\item $M \in \textbf{List TLabel}$: sequence of zero or more \textbf{TLabel}. We will use list notation standard to functional programming languages.
\end{itemize}
defined as the smallest relation following the following schema:
\begin{mathpar}
\inferrule{}{\langle \boldsymbol{0}, \Sigma, \mathscr{C} \rangle \Downarrow^{[]} \Sigma}
\and
\inferrule{
	\langle C, \Sigma, \mathscr{C} \rangle \xrightarrow{\mu} \langle C', \Sigma', \mathscr{C} \rangle \and \langle C', \Sigma', \mathscr{C} \rangle \Downarrow^M \Sigma''
}{
	\langle C, \Sigma, \mathscr{C} \rangle \Downarrow^{\mu :: M} \Sigma''
}
\end{mathpar}

We can, thus, now state the \emph{termination insensitive non-interference theorem} as follows:
\begin{align} \label{main:def}
\begin{split}
	&\Delta;\Gamma;\bot \vdash C \Rightarrow
	\Sigma_1 \equiv^\Gamma_{low} \Sigma_2 \\ \Rightarrow\ &\langle C, \Sigma_1, \mathscr{C}\rangle \Downarrow^{M_1} \Sigma'_1
	\Rightarrow\ \langle C, \Sigma_2, \mathscr{C}\rangle \Downarrow^{M_2} \Sigma'_2 \\ \Rightarrow\ &\Sigma'_1 \equiv^\Gamma_{low} \Sigma'_2
\end{split}
\end{align}

\medskip

\noindent
To justify this statement, we rely on a small set of proof obligations that connect typing, expression evaluation, and the operational/denotational semantics. Each obligation is stated formally and followed by a short explanation of the intuition behind it.

\subsubsection{Properties of procedure context}
The main intuition behind the introduction of $\Delta$ for typing procedure calls was explained previously.

\paragraph{Context subsumption}
We say that \(\Delta\) satisfies \emph{context subsumption} if lowering the control level always maintains typing:
\begin{equation}\label{ass:ctx_sub}
  \Gamma \in \Delta~X~pc\ \wedge\ pc' \sqsubseteq pc
  \ \Longrightarrow\
  \Gamma \in \Delta~X~pc'
\end{equation}

Typing a call to \(X\) that is valid under a more restrictive (higher) control
  \(pc\) must remain valid when the analysis proves that control has become more public.
  This is used in the soundness proof whenever we \emph{lower} the current program counter along a derivation (e.g., after leaving a high guard).

\paragraph{Well-formed procedure context}
We say that the procedure context \(\mathscr{C}\) is \emph{well formed} if every procedure lists all the participants that actually appear in its body. Formally, for every definition \(X(\vec{p}) = C \in \mathscr{C}\),
\begin{equation} \label{ass:wellf_ctx}
  \pn(C) \subseteq \{\vec{p}\}.
\end{equation}

This property ensures that the interface \(X(\vec{p})\) exposes exactly the processes that \(C\) may mention, preventing references to undeclared processes and simplifying the typing of calls. In addition to this, this notion of \emph{well-formedness} for the procedure context is a less stringent version of the notion given by Montesi's book\cite{montesi2023introduction}.
The other properties needed for a context to be well-formed go beyond the scope of this thesis, thus we will omit them.

\paragraph{Well-typed security procedure context}
We require the typing context \(\Delta\) to be consistent with the declaration context \(\mathscr{C}\): every declared procedure must typecheck under every security environment that \(\Delta\) admits for it (at any program counter). Formally, for every clause \(X(\vec{p}) = C \in \mathscr{C}\) and every \(pc \in \mathscr{L}\),
\begin{equation}\label{ass:wellt_ctx}
  \Delta~X~pc = \mathcal{G}
  \;\Longrightarrow\;
  \forall\,\Gamma \in \mathcal{G}.\ \Delta;\Gamma;pc \vdash C
\end{equation}
Here \(\mathcal{G}\) is the set of admissible security environments for the body \(C\) at program counter \(pc\).
It is allowed that, for some \(X\) and \(pc\), the lookup yields an empty set of admissible environments, i.e.,\ \(\Delta(X,pc)=\varnothing\).
In that case, no \(\Gamma\) can satisfy the side condition \(\Gamma \in \mathcal{G}\) in the typing rule for calls to \(X\), so any call to \(X\) at that \(pc\) is untypable: the derivation stops at the \(\Delta\)-lookup premise. Intuitively, this expresses that \(X\) cannot be used at program counter \(pc\).

\paragraph{Freshness of formal parameters.}
\label{ass:fresh}
We assume a Barendregt-style convention for procedure parameters\cite{barendregt1984lambda}: in the procedure-definition context \(\mathscr{C}\), all formal parameters are chosen \emph{sufficiently fresh}. Concretely, for every clause \(X(\vec{p}) = C \in \mathscr{C}\):
\begin{enumerate}
  \item the names in \(\{\vec{p}\}\) are pairwise distinct;
  \item for every other choreography $C'$ s.t. \(C \neq C'\), the parameters \(\{\vec{p}\}\) do not clash with the process names that occur in \(C'\):
  \[
    \{\vec{p}\} \cap \pn(C') = \varnothing.
  \]
\end{enumerate}
Intuitively, parameters bind the process names used inside \(C\); by choosing them distinct and disjoint from the names mentioned elsewhere we avoid spurious name capture when instantiating \(X\) with actual participants (e.g., at call sites or during inlining). We will use \(\alpha\)-renaming implicitly to maintain this invariant.

\subsubsection{Properties of expressions}
The semantics referenced\cite{montesi2023introduction} is mostly underspecified when dealing with local expressions, with no indication on how to evaluate them in the general case.
We wish to keep as close as possible to the reference, thus, we abstain from specifying a concrete semantics.
We will limit ourselves to constraining local evaluation to being \emph{deterministic}.
Formally, given a process store $\sigma$, expression $e$, and two values $v_1, v_2$:
$$
\sigma \vdash e \downarrow v_1 \Rightarrow
\sigma \vdash e \downarrow v_2 \Rightarrow v_1 = v_2
$$
We assume this to prevent guards and right-hand sides from introducing spurious non-determinism that a low observer could notice.

\section{Instrumented Choreographies}
A natural strategy to prove the main theorem stated in (\ref{main:def}) is to use induction on the length of the computation. Unfortunately, this approach is not sufficient: given the small-step nature of the semantics we need to \emph{carry over} some information from previous execution states.
More concretely, given a flow policy, the same configuration state could be non-interferent or not depending on previous states in the computation. Let us see an example:
$$ \text{if } p.(a == 0) \text{ then } p.x := 0; ~ \boldsymbol{0} \text{ else } p.x := y + z; ~ \boldsymbol{0}; ~ \boldsymbol{0} $$
We know that this choreography follows non-interference for some flow-policy. Let us denote the choreography with $C$.
Given a $\mathscr{C}$ and $\Sigma_1, \Sigma_2$ such that $\Sigma_1~p.a = 0, \Sigma_2~p.a = 1$ then we have the following transitions:
\begin{align*}
	\langle C, \Sigma_1, \mathscr{C} \rangle &\xrightarrow{\tau @p}
	\langle p.x := 0;~ \boldsymbol{0}, \Sigma_1, \mathscr{C} \rangle \\
	\langle C, \Sigma_2, \mathscr{C} \rangle &\xrightarrow{\tau @p}
	\langle p.x := y + z;~ \boldsymbol{0}, \Sigma_2, \mathscr{C} \rangle
\end{align*}
Clearly, 
$$p.x := 0;~ \boldsymbol{0} \ne p.x := y + z;~ \boldsymbol{0}$$
thus the induction hypothesis could not be used. To solve this, we need a way to be able to differentiate when choreographies are able to be different and when they are not.

We do this by introducing \emph{brackets} around code able to differ.

\paragraph{Intuition:} Given a fixed element \textit{low} in $\MCL$, we consider anything inside brackets as being \emph{not observable} by a participant of level $l \sqsubseteq \textit{low}$. We call this participant a \emph{low-observer}.

\subsection{Syntax}
We instrument choreographies with \emph{brackets} to mark code fragments that are allowed to differ across alternative executions. The syntax of (instrumented) choreographies is given below; expressions are left abstract.

\begin{align*}
p,q &\in \mathsf{Pid}            && \text{(process names)}\\
x   &\in \mathsf{Var}          && \text{(local variables)}\\
X   &\in \mathsf{ProcName}       && \text{(procedure names)}\\
L   &\in \mathsf{Label}          && \text{(selection labels)}\\
e   &\in \mathsf{Expr}           && \text{(expressions)}
\end{align*}

\noindent Choreographies:
\[
\begin{array}{rcll}
C \in \mathsf{[Chor]} \;\metaDeff\;
  & \boldsymbol{0}                          & & \text{(termination)}\\
\mid& C_1 \mathbin{;} C_2                   & & \text{(sequencing)}\\
	\mid& [C] & & \text{(bracketed fragment)}\\
\mid& p.x \mathrel{:=} e                    & & \text{(assignment)}\\
\mid& p.e \;\rightarrow\; q.x               & & \text{(communication)}\\
\mid& \mathbf{if}\; p.e\; \mathbf{then}\; C_1\; \mathbf{else}\; C_2
                                           & & \text{(conditional at }p\text{)}\\
	\mid& X(\vec{p}\,)        & & \text{(procedure call with participants)}
\end{array}
\]

We note that $\mathsf{[Chor]}$ differs from $\mathsf{Chor}$ on a few key points.
\begin{itemize}
	\item \emph{Flattening of instructions and choreographies:} We want to be able to put inside the brackets a sequence of instructions of arbitrary length (possibly zero), thus we want to be able to denote as different terms, for example, $[\boldsymbol{0}]$ and $\boldsymbol{0}$.
	\item \emph{Removal of the runtime term and label selection instructions:} This is not necessary but it simplifies the soundness proof. Its justification is that both instructions have no impact on the final computed stores and are needed by choreographies to deal with projection\cite{montesi2023introduction}, which goes beyond the scope of this thesis.
\end{itemize}

\subsection{Lowering and Lifting of $\mathsf{[Chor]}$}
We introduce an operator $\lfloor \cdot \rfloor: \textbf{[Chor]} \rightarrow \textbf{Chor}$ that \emph{removes} the instrumentation from a choreography. The operator is defined by recursion on the structure of $C$:
\begin{align*}
\lfloor \boldsymbol{0}\rfloor & \triangleq \boldsymbol{0} \\
\lfloor C_1 \mathbin{;} C_2\rfloor & \triangleq \lfloor C_1 \rfloor \fatsemi \lfloor C_2 \rfloor\\
\lfloor [C] \rfloor & \triangleq \lfloor C \rfloor\\
	\lfloor p.x \mathrel{:=} e \rfloor & \triangleq p.x \mathrel{:=} e; \boldsymbol{0}\\
	\lfloor p.e \;\rightarrow\; q.x \rfloor & \triangleq p.e \;\rightarrow\; q.x; \boldsymbol{0}\\
\lfloor \mathbf{if}\; p.e\; \mathbf{then}\; C_1\; \mathbf{else}\; C_2 \rfloor
	& \triangleq \mathbf{if}\; p.e\; \mathbf{then}\; \lfloor C_1\rfloor\; \mathbf{else}\; \lfloor C_2 \rfloor; \boldsymbol{0}\\
	\lfloor X(\vec{p})\rfloor & \triangleq X(\vec{p}); \boldsymbol{0}
\end{align*}
We also define an operator $\lceil \cdot \rceil$ that turns a \textbf{Chor} into the corresponding \textbf{[Chor]} by copying its shape.

We note that not every \textbf{Chor} is in the domain of $\lceil \cdot \rceil$.
As a demonstrating example, let us consider:
$$
\lceil p \rightarrow q[L]; \boldsymbol{0} \rceil
$$
We would not know how to create an equivalent term in \textbf{[Chor]}.
This problem will be properly addressed in \ref{chap:compl}. For now, we will just define $\lceil \cdot \rceil$ as being \emph{the inverse of lowering}, defined by the following equation:
\begin{equation}\label{defs:lift_chor}
C = \lfloor \lceil C \rceil \rfloor
\end{equation}

Both lowering and lifting are defined also on \emph{procedure context}, as follows:
\begin{align*}
	\lfloor \mathscr{C} \rfloor &\triangleq
\{X(\vec{p}) = \lfloor C \rfloor \mid X(\vec{p}) = C \in \mathscr{C}\}\\
	\lceil \mathscr{C} \rceil &\triangleq
\{X(\vec{p}) = \lceil C \rceil \mid X(\vec{p}) = C \in \mathscr{C}\}\\
\end{align*}

\subsection{Low Equivalence of $\mathsf{[Chor]}$}
We write \(C_1 \,\approx_{\mathsf{low}}\, C_2\) to denote \emph{low–equivalence} between choreographies.
Intuitively, \(\approx_{\mathsf{low}}\) compares choreographies structurally, but \emph{forgets the
contents of bracketed fragments}: any two bracketed subterms are considered equivalent,
independently of what they contain.\\
Formally, \(\approx_{\mathsf{low}}\) is the \emph{least} relation on \(\mathsf{[Chor]}\) closed under the following rules:
\[
\infer
  {C_1 \approx_{\mathsf{low}} C_2 \quad\; C_1' \approx_{\mathsf{low}} C_2'}
  {\,C_1 \mathbin{;} C_1' \;\approx_{\mathsf{low}}\; C_2 \mathbin{;} C_2'\,}
\qquad
\infer
  {}
  {\,[C_1] \;\approx_{\mathsf{low}}\; [C_2]\,}
\]
\[
\infer
 {p = p' \quad e = e' \quad C_{11} \approx_{\mathsf{low}} C_{21} \quad C_{12} \approx_{\mathsf{low}} C_{22}}
 {\,\mathbf{if}\; p.e\; \mathbf{then}\; C_{11}\; \mathbf{else}\; C_{12}
   \;\approx_{\mathsf{low}}\;
   \mathbf{if}\; p'.e'\; \mathbf{then}\; C_{21}\; \mathbf{else}\; C_{22}\,}
\]

\noindent For all the remaining constructors, low–equivalence coincides with syntactic equality (shape and parameters must match). Concretely:
\[
\boldsymbol{0} \;\approx_{\mathsf{low}}\; \boldsymbol{0},\qquad
p.x \mathrel{:=} e \;\approx_{\mathsf{low}}\; p.x \mathrel{:=} e,\qquad
p.e \rightarrow q.x \;\approx_{\mathsf{low}}\; p.e \rightarrow q.x,
\]
\[
	X(\vec{p}\,)\;\approx_{\mathsf{low}}\; X(\vec{p}\,)
\]

By construction, \(\approx_{\mathsf{low}}\) is an equivalence relation for sequencing and conditionals; its only non-syntactic identification is the equation of  bracketed fragments.

\subsection{Well-Formedness of \textbf{[CStore]}}
Before being able to present the instrumented semantics, we need to instrument the \textbf{CStore} to encode the same notion of \emph{value not observable by a low-observer}.

We do this by extending the previous definitions, we introduce a difference between a \emph{value} and a \emph{high-value} (i.e., bracketed value).
\begin{align*}
	\mathsf{[CStore]}:&~\mathsf{PName} \rightarrow \mathsf{[PStore]}\\
	\mathsf{[PStore]}:&~\mathsf{Var} \rightarrow \mathsf{[Val]}\\
	\mathsf{[Val]}:&~ \mathsf{Val}~|~[~~\mathsf{Val}~~]
\end{align*}

We then say that a \textbf{[CStore]} $[\Sigma]$ is \emph{well formed} with respect to a $\Gamma$ (i.e., $\Gamma \vdash [\Sigma]$) when the following property is satisfied for all $p, x, v$:
$$
	[\Sigma]~p~x = [v] \iff \Gamma~p~x \not\sqsubseteq low
$$
Thus, encoding with $\sqsubseteq$ the notion of \emph{observability}: $a \not\sqsubseteq low$ means that $low$ can not \emph{see} the value of $a$

The extension of \emph{well-formedness} to \textbf{[PStore]} is natural.

As we did for choreographies, we define a \emph{lifting} function $\lceil \cdot \rceil^\Gamma$ for \textbf{CStore}. The main difference is that the lifting function will maintain well-formedness of the created \textbf{[CStore]} with respect to $\Gamma$. That is, it will choose bracketing of values depending on the security label in $\Gamma$ of the associated variables.

\subsection{Correctness of \textbf{[CStore]}}
We define a function $\lfloor \cdot \rfloor$ polimorfically on \textbf{[Val]}, \textbf{[PStore]}, and \textbf{[CStore]}. This function \emph{lowers} the bracketed object to its reference counterpart.
Formally, given a \textbf{[Val]} object $\upnu$
$$
\upnu \mapsto \begin{cases}
	&v \quad \text{if $\upnu = [v]$}\\
    &v \quad \text{if $\upnu = v$}
    \end{cases}
$$
From now on, every occurrence of $v$ has to be considered as either a \textbf{Val} object or a \textbf{[Val]} object which is \emph{not bracketed}. Every occurrence of $[v]$ is a \emph{bracketed} \textbf{[Val]}. We will use $\upnu$ when it is not specified whether the object is bracketed or not.\\
We extend the \emph{lowering} function to \textbf{PStore} and \textbf{CStore} by applying it to every stored value.

We say that a \textbf{[CStore]} $[\Sigma]$ is \emph{correct} with respect to $\Sigma$ when
$$
\lfloor [\Sigma] \rfloor = \Sigma
$$

The extension of \emph{correctness} to \textbf{[PStore]} is natural.


\subsection{Low Equivalence on \textbf{[CStore]}}
We define a notion of low-equivalence on \textbf{[Val]}: Given $\upnu_1, \upnu_2$ then
\begin{equation}
\upnu_1 \approx_{low} \upnu_2
\quad\text{iff}\quad
\begin{cases}
\upnu_1 = v_1~\text{and}~\upnu_2 = v_2~\text{and}~v_1 = v_2\\
\text{or}\\
\upnu_1 = [v_1]~\text{and}~\upnu_2 = [v_2]
\end{cases}
\end{equation}

We extend the previous notion of $low$-equivalence between stores to exploit the bracket notation. Formally given $[\Sigma_1], [\Sigma_2]$, then $[\Sigma_1] \approx_{low} [\Sigma_2]$ if, for every $p, x$, then
$$
[\Sigma_1]~p~x \approx_{low} [\Sigma_2]~p~x
$$

The extension of \emph{low-equivalence} to \textbf{[PStore]} is natural.


\subsection{Semantics}

We fix an observation level $low \in \MCL$ and a choreographic security labeling $\Gamma$. We define the new small-step operational semantics as:
\[
	\langle C,[\Sigma],\mathscr{C} \rangle \rightarrow \langle C',[\Sigma]',\mathscr{C} \rangle
\]

\noindent\textbf{Assignments}
\begin{mathpar}
\inferrule*{
	[\Sigma]~p \vdash e \downarrow v \\
  \Gamma\,p\,x \not\sqsubseteq low
}{
	\langle p.x := e,~[\Sigma],\ \mathscr{C} \rangle
  \rightarrow
	\langle \boldsymbol{0},\ [\Sigma][p.x \mapsto [v]],\ \mathscr{C} \rangle
}

\inferrule*{
	[\Sigma]~p \vdash e \downarrow [v]
}{
	\langle p.x := e,\ [\Sigma],\ \mathscr{C} \rangle
  \rightarrow
	\langle \boldsymbol{0},\ [\Sigma][p.x \mapsto [v]],\ \mathscr{C} \rangle
}

\inferrule*{
	[\Sigma]~p \vdash e \downarrow v \\
  \Gamma\,p\,x \sqsubseteq low
}{
	\langle p.x := e,\ [\Sigma],\ \mathscr{C} \rangle
  \rightarrow
	\langle \boldsymbol{0},\ [\Sigma][p.x \mapsto v],\ \mathscr{C} \rangle
}
\end{mathpar}

\noindent\textbf{Communications}
\begin{mathpar}
\inferrule*{
	[\Sigma]~p \vdash e \downarrow v \\
  \Gamma\,q\,x \not\sqsubseteq low
}{
	\langle p.e \rightarrow q.x,\ [\Sigma],\ \mathscr{C} \rangle
  \rightarrow
	\langle \boldsymbol{0},\ [\Sigma][q.x \mapsto [v]],\ \mathscr{C} \rangle
}

\inferrule*{
	[\Sigma]~p \vdash e \downarrow [v]
}{
	\langle p.e \rightarrow q.x ,\ [\Sigma],\ \mathscr{C} \rangle
  \rightarrow
	\langle \boldsymbol{0},\ [\Sigma][q.x \mapsto [v]],\ \mathscr{C} \rangle
}

\inferrule*{
	[\Sigma]~p \vdash e \downarrow v \\
  \Gamma\,q\,x \sqsubseteq low
}{
	\langle p.e \rightarrow q.x ,\ [\Sigma],\ \mathscr{C} \rangle
  \rightarrow
	\langle \boldsymbol{0},\ [\Sigma][q.x \mapsto v],\ \mathscr{C} \rangle
}
\end{mathpar}

Intuitively, these instrumented semantics for assignment and communication are needed to preserve the well-formedness invariant of \textbf{CStore}.
Let us look at the assignment rules, since the communication ones follow similarly:
\begin{itemize}
\item If the destination cell is not low-observable (\(\Gamma\,p\,x \not\sqsubseteq low\)), we always store a bracketed value: \([\Sigma][p.x \mapsto [v]]\). This preserves the invariant that \([\Sigma]~p~x\) is bracketed exactly when \(\Gamma\,p\,x\) is not observable at \(low\).
\item If the expression already evaluates to a bracketed value \([v]\), we propagate the bracket on write. This never \emph{un-brackets} high information and thus cannot violate well-formedness (by soundness with respect to explicit flow well-typed programs will not allow storing \([v]\) into a low-labeled location).
\item If the destination is low-observable (\(\Gamma\,p\,x \sqsubseteq low\)) and the expression evaluates to an un-bracketed \(v\), we update with \(v\) (no brackets). This prevents spurious brackets in low cells and maintains that only non-low-observable locations carry bracketed values.
\end{itemize}

\noindent\textbf{Conditionals}
\begin{mathpar}
\inferrule*{
	[\Sigma]~p \vdash e \downarrow [\mathit{true}]
}{
	\langle \mathbf{if}\ p.e\ \mathbf{then}\ C_1\ \mathbf{else}\ C_2,\ [\Sigma],\ \mathscr{C} \rangle
  \rightarrow
	\langle [C_1],\ [\Sigma],\ \mathscr{C} \rangle
}

\inferrule*{
	[\Sigma]~p \vdash e \downarrow \mathit{true}
}{
	\langle \mathbf{if}\ p.e\ \mathbf{then}\ C_1\ \mathbf{else}\ C_2,\ [\Sigma],\ \mathscr{C} \rangle
  \rightarrow
	\langle C_1,\ [\Sigma],\ \mathscr{C} \rangle
}

\inferrule*{
	[\Sigma]~p \vdash e \downarrow [v] \\ v \neq \mathit{true}
}{
	\langle \mathbf{if}\ p.e\ \mathbf{then}\ C_1\ \mathbf{else}\ C_2,\ [\Sigma],\ \mathscr{C} \rangle
  \rightarrow
	\langle [C_2],\ [\Sigma],\ \mathscr{C} \rangle
}

\inferrule*{
	[\Sigma]~p \vdash e \downarrow v \\ v \neq \mathit{true}
}{
	\langle \mathbf{if}\ p.e\ \mathbf{then}\ C_1\ \mathbf{else}\ C_2,\ [\Sigma],\ \mathscr{C} \rangle
  \rightarrow
	\langle C_2,\ [\Sigma],\ \mathscr{C} \rangle
}
\end{mathpar}

Intuitively, the bracketed rules capture the dependency of control flow on information not observable at \(low\). If the guard reduces under \([\Sigma]\) to a \emph{bracketed} truth value, then the selected continuation is executed in bracketed form \([C_i]\): this explicitly records that the branch choice depends on data above \(low\) and, via the assignment and communication rules, forces all subsequent effects to remain bracketed and thus invisible at \(low\). Dually, when the guard evaluates to an \emph{un-bracketed} boolean, the choice is already determined at \(low\), so the corresponding un-bracketed continuation \(C_i\) proceeds normally.

\noindent\textbf{High-step}
\begin{mathpar}
\inferrule*{
	\langle C,\ [\Sigma],\ \mathscr{C} \rangle \rightarrow \langle C',\ [\Sigma]',\ \mathscr{C} \rangle
}{
	\langle [C],\ [\Sigma],\ \mathscr{C} \rangle \rightarrow \langle [C'],\ [\Sigma]',\ \mathscr{C} \rangle
}

\inferrule*{ }{
	\langle [\boldsymbol{0}],\ [\Sigma],\ \mathscr{C} \rangle \rightarrow \langle \boldsymbol{0},\ [\Sigma],\ \mathscr{C} \rangle
}
\end{mathpar}

\noindent\textbf{Sequencing}
\begin{mathpar}
\inferrule*{
	\langle C_1,\ [\Sigma],\ \mathscr{C} \rangle \rightarrow \langle C_1',\ [\Sigma]',\ \mathscr{C} \rangle
}{
	\langle C_1 \, ; \, C_2,\ [\Sigma],\ \mathscr{C} \rangle \rightarrow \langle C_1' \, ; \, C_2,\ [\Sigma]',\ \mathscr{C} \rangle
}

\inferrule*{ }{
	\langle \boldsymbol{0} \, ; \, C,\ [\Sigma],\ \mathscr{C} \rangle \rightarrow \langle C,\ [\Sigma],\ \mathscr{C} \rangle
}
\end{mathpar}

\noindent\textbf{Procedure calls}
\begin{mathpar}
\inferrule*{
	X(\vec q)= C \in \mathscr{C}
}{
	\langle X(\vec p), [\Sigma],\ \mathscr{C} \rangle \rightarrow \langle C[\vec q/\vec p],\ [\Sigma],\ \mathscr{C} \rangle
}
\end{mathpar}

\paragraph{Multi-step transitions}
For notational ease, we define $\cdot \twoheadrightarrow \cdot$ as the transitive, reflexive closure of $\cdot \rightarrow \cdot$.

\paragraph{Local expression evaluation}
Expression evaluation is a natural extension to the one presented in the reference semantics. The only aspect which needs careful consideration is the extension to \textbf{[Val]} of $~\vdash f(\vec{v}) \downarrow \upnu$.
The extension \emph{carries} brackets from the arguments of the function to its returned values, that is: given a function
$$
f: \textbf{Val}^{*} \rightarrow \textbf{Val}
$$
we define a \emph{lifted} $[f]$ s.t. for every $\vec{\upnu}, \vec{v}$ s.t.
$\lfloor \vec{\upnu} \rfloor = \vec{v}$ then
$\lfloor f(\vec{\upnu}) \rfloor = f(\vec{v}) $
and, if is exists $v_i, \upnu_i$ s.t. $\upnu_i \in \vec{\upnu} \land \upnu_i = [v_i]$ then, there exists $v~$ s.t. $ [f](\vec{\upnu}) = [v] $.


This makes our evaluation relation \emph{correct} with respect to the reference (proved by simple structural induction). In this context, we define correctness as returning an object that, once lowered, it agrees with the reference implementation.\\
Formally:
\begin{equation}\label{inst:loc_correct}
\lfloor [\sigma] \rfloor \vdash e \downarrow v \Leftrightarrow ( [\sigma] \vdash e \downarrow \upnu \land \lfloor \upnu \rfloor = v )
\end{equation}

It is to be noted that this property, combined with assuming the reference evaluation as deterministic, makes local expression evaluation for the instrumented semantics deterministic aswell.

\subsection{Extension of the Type System}
Most of the type system for \textbf{[Chor]} carries over from the one for \textbf{Chor}, with a new rule to type \emph{bracketed choreographies}:
$$
  \inferrule
  {\Delta;\Gamma;\ell' \vdash \; C  \quad pc \sqsubseteq \ell' \quad \ell' \not\sqsubseteq low}
  {\Delta;\Gamma;pc \vdash \; [C]}
$$
This rule makes sure that the content of $C$ can be typed as high, ensured by the first and last premise.\\
The second premise enforces that the label attached to the difference, \(\ell'\), \emph{dominates} the ambient program counter. In this way all influences of the current control flow, the implicit flows tracked by \(pc\), are subsumed by the bracket’s label \(\ell'\).

\section{Auxiliary Lemmas}
To be able to prove the main non-interference theorem as defined in \ref{main:def}, we will firstly assume a few auxiliary lemmas. Since the majority of the proof approach is taken directly from \cite{myers2011proving}, we will abstain from reproducing them in this work when sufficiently similar.

\subsection{Completeness Lemma}\label{chap:compl}
Completeness is stated as follows:\\
For each
$$
\langle C, \Sigma, \mathscr{C} \rangle \Downarrow^M \Sigma'
$$
There exists $[\Sigma]'$ such that:
\begin{equation}
\label{aux:compl}
	\langle \lceil \wr C \wr \rceil, \lceil \Sigma \rceil^\Gamma, \lceil \mathscr{C} \rceil \rangle \Downarrow [\Sigma]'
\land \lfloor [\Sigma]' \rfloor = \Sigma'
\end{equation}

The operator $\wr \cdot \wr$ will transform $C$ into the subset of \textbf{Chor} for which
$\lceil \cdot \rceil$ is well-defined. Part of the completeness proof will be showing that the operator has no influence on the natural semantics.

Since \textbf{Chor} and \textbf{[Chor]} have multiple small but significant differences, we proceed the completeness proof by composing consecutive steps.

\subsubsection{Removal of Non-determinism in the Semantics}
We can easily verify how the semantics given in \ref{background:choreographies} is non-deterministic (\emph{i.e.}, out-of-order): given the same configuration it can admit multiple, different, execution steps. It is also to be noted that the instrumented semantics is defined as fully deterministic: any configuration that admits an execution step admits just one.
%Confluence means that is proving that all maximal executions from the same state yield the same observable result.

The first step to reach completeness is to prove that this non-determinism can be discarded.
This goal is achieved by considering a semantics for choreography where the rules DELAY, DELAY-COND are omitted and where the rule CALL-FIRST has the following form:
\bigskip

\noindent\makebox[\textwidth][c]{\resizebox{1.0 \textwidth}{!}{$
    \inferrule*[right=call-first] { X(\vec{q}~) = C \in \mathscr{C} \\ \vec{p} = p_1, \ldots, p_n }
	{\langle X(\vec{p}~);C', \Sigma, \mathscr{C} \rangle \xrightarrow{\tlint{p_1}} \langle p_2 : X(\vec{p}~).C'; \ldots; p_n : X(\vec{p}~).C'; C[\vec{q}/\vec{p}~] \fatsemi C', \Sigma, \mathscr{C} \rangle}
$}}

\bigskip
\noindent It is to be noted how the new CALL-FIRST is a special case of the previous one. This leads us to see how deterministic transitions are a subset of the transitions admitted in the reference semantics.

The proof of completeness of the deterministic semantics follows from the work from Cruz-Filipe, Montesi, and Peressotti\cite{cruz2023formal}\footnote{The language and semantics defined in the paper have some trivial differences, yet it is easy to see how the proofs presented there can be carried over to the language and semantics used in this thesis.} which proves some important properties of the semantics, those being:
\begin{itemize}
\item\emph{deadlock freedom:} Any choreography that is not $\boldsymbol{0}$ can execute.
\item\emph{diamond property:} Any two distinct one-step reductions from the same state are reconcilable: there exist further reductions from each successor that lead to an identical state.
\item\emph{convergence:} Any two executions of a choreography that end
in a terminated choreography must finish in the same state.
\end{itemize}

\begin{wrapfigure}{r}{0.35\textwidth}
  \centering
\begin{tikzpicture}[x=1cm,y=1cm, every node/.style={font=\small}]
  %--- Nodes placed to mimic the photo ----------------------------------------
  \node (C)   at (0,0) {$C$};
  \node (C2)  at (1,-1) {$C_2$};
  \node (C2p) at (3,-3) {$C_2'$};
  \node (C1)  at (-1, -1) {$C_1$};
  \node (C1p) at (0,-2) {$C_1'$};
  \node (Cp)  at (2,-4) {$C'$};

  %--- Top/right branch --------------------------------------------------------
  \draw[->] (C) -- node[right=4pt] {$\mu_2$} (C2);
  \node[cross out,draw,thick,minimum size=5pt,inner sep=0pt]
       at ($(C)!0.45!(C2)$) {};

  \draw[->] (C) -- node[left=4pt] {$\mu_1$} (C1);
  \draw[->, densely dashed] (C2) -- node[above=2pt] {$\mu_1$} (C1p);

  \draw[->] (C1) -- node[left=4pt] {$\mu_2$} (C1p);

  \node[cross out,draw,thick,minimum size=5pt,inner sep=0pt]
       at ($(C1)!0.35!(C1p)$) {};

  \draw[markarrows] (C2) -- node[right=4pt] {$M$} (C2p);
  \node[cross out,draw,thick,minimum size=5pt,inner sep=0pt]
       at ($(C2)!0.25!(C2p)$) {};

  \draw[markarrows] (C1p) -- node[left=4pt] {$M$} (Cp);
  \node[cross out,draw,thick,minimum size=5pt,inner sep=0pt]
       at ($(C1p)!0.25!(Cp)$) {};

  \draw[->] (C2p) -- node[right=4pt] {$\mu_1$} (Cp);
  \node[cross out,draw,thick,minimum size=5pt,inner sep=0pt]
       at ($(C2p)!0.45!(Cp)$) {};

\end{tikzpicture}
\end{wrapfigure}

\noindent Using the previously stated properties, we proceed by a graphical proof: $C$ is able to do a step in the reference semantics and reach a $C_1$ configuration, while in the deterministic semantics (denoted with the crossed arrow) $C$ reaches a \emph{different} $C_2$.
By the diamond property, there is a $\mu_1$ from $C_2$ to $C_1'$ (depicted as a dashed arrow). Since we can \emph{compose diamonds}, we can repeat this step the zero or more times necessary to \emph{wait} for $\mu_1$ to be deterministic.
Moreover no maximal computation can end with a non-deterministic transition (which is a trivial corollary of deadlock freedom) which gives us the existence of this transition.
Thus, assuming the computation from $C$ as terminating in the reference semantics, it is always reachable a common configuration $C'$ from both $C_1$ and $C_2$ using the deterministic semantics.\\
It is easy to see, by cases on the reference semantics, how, if from $C$ there are no two different one-step reachable $C_1, C_2$, then the transition is in the deterministic subset.

The new semantics is deterministic as defined above: any configuration that admits an execution step admits just one, completely specified by the first instruction of the choreography. From now on, the deterministic semantics will be the semantics considered for \textbf{Chor}.

\subsubsection{Removal of Irrelevant Terms}
We want to prove that terms not present in the image of $\lfloor \cdot \rfloor$ are not relevant to natural semantics, making us able to use freely the $\lceil \cdot \rceil$ operator. We introduce the operator $\wr C \wr$ defined by structural recursion on $C$ as follows:
\begin{align*}
	\wr~\boldsymbol{0}~\wr &\triangleq \boldsymbol{0} \\
	\wr~p.e \rightarrow q.x;~ C'~\wr &\triangleq p.e \rightarrow q.x;~ \wr C' \wr \\
	\wr~p \rightarrow q[L];~ C'~\wr &\triangleq \wr C' \wr \\
	\wr~p.x := e;~ C'~\wr &\triangleq p.x := e;~ \wr C' \wr \\
	\wr~\text{if } p.e \text{ then } C_1 \text{ else } C_2;~ C'~\wr &\triangleq \text{if } p.e \text{ then } \wr C_1\wr \text{ else } \wr C_2\wr ;~ \wr C'\wr \\
	\wr~X(\vec{p}~);~ C'~\wr &\triangleq X(\vec{p}~);~ \wr C' \wr \\
	\wr~q : X(\vec{p}~).C;~ C'~\wr &\triangleq \wr C' \wr \\
\end{align*}
It is easy to verify how, for any $C$, $\lceil \wr C \wr \rceil$ is well-defined as by definition \ref{defs:lift_chor}.

We extend the operator $\wr \cdot \wr$ on \emph{procedure context}, as follows:
$$
\wr\mathscr{C}\wr \triangleq
\{X(\vec{p}) = \wr C \wr \mid X(\vec{p}) = C \in \mathscr{C}\}
$$

We now prove that this operator is complete with respect to the semantics: for each $C$ such that
$$
\langle C, \Sigma, \mathscr{C} \rangle \Downarrow^M \Sigma'
$$

There exists $M^*$ such that:
\begin{equation}
\label{aux:compl_wr}
	\langle \wr C \wr, \Sigma, \wr\mathscr{C}\wr \rangle \Downarrow^{M^*} \Sigma'
\end{equation}

\noindent \textbf{Proof:}\\
We proceed by induction on the size of $M$
\begin{itemize}
	\item \emph{size: 0} In this case the $C = \boldsymbol{0}$ and by definition
		$\wr C \wr = \boldsymbol{0}$, thus the conclusion holds.
	\item \emph{size: n+1} In this case we have two hypothesis:
		\begin{align}
			\langle C, \Sigma, \mathscr{C} \rangle& \xrightarrow{\mu}
			\langle C', \Sigma', \mathscr{C} \rangle& \tag{H1} \label{aux:compl_wr_h1}\\
			\exists M',~\langle \wr C'\wr, \Sigma', \wr \mathscr{C} \wr \rangle& \Downarrow^{M'} \Sigma'' \tag{IH} \label{aux:compl_wr_ih}
		\end{align}
		By inversion of (\ref{aux:compl_wr_h1}) we find that $C = I; C^\star$, we proceed by cases on the structure of $I$:
		\begin{itemize}
			\item \emph{assign, communication}: By further inversion of (\ref{aux:compl_wr_h1}) we find $C^\star = C'$.\\
			We now find:
			$$\wr C \wr = \wr I; C^\star \wr = \wr I; C' \wr = I;~\wr C' \wr$$
				Using (\ref{aux:compl_wr_ih}) we construct $M^* = \mu :: M'$
			\item \emph{selection, runtime term}:
				By further inversion of (\ref{aux:compl_wr_h1}) we find $C^\star = C'$ and $\Sigma = \Sigma'$.\\
			We now find:
			$$\wr C \wr = \wr I; C^\star \wr = \wr I; C' \wr = \wr C' \wr$$
				Using (\ref{aux:compl_wr_ih}) we construct $M^* = M'$
			\item \emph{function call}: By further inversion of (\ref{aux:compl_wr_h1}) we find $X(\vec{p}) = C_X \in \mathscr{C}$, $C' = p_2 : X(\vec{p}~).C^\star; \ldots; p_n : X(\vec{p}~).C^\star; C_X[\vec{q}/\vec{p}~] \fatsemi C^\star$ and $\Sigma = \Sigma'$\\
			We now find:
				$$\wr C \wr = \wr X(\vec{p}); C^\star \wr = X(\vec{p}); \wr C^\star \wr$$
			Which can do a $\mu$ step of the operational semantics and reach:
				$$p_2 : X(\vec{p}~).C^\star; \ldots; p_n : X(\vec{p}~).C^\star; \wr C_X\wr[\vec{q}/\vec{p}~] \fatsemi \wr C^\star \wr$$
			Which can do $n-1$ steps $\tau@p_2, \ldots, \tau@p_n$ and reach
				$$\wr C_X\wr[\vec{q}/\vec{p}~] \fatsemi \wr C^\star \wr$$
				We now look at $C'$ and notice, by reasoning on the definition of \emph{sequential composition} and \emph{process substitution} (proven in Appendix \ref{appdix:A}):
				\begin{align*}
					\wr C' \wr &= \wr p_2 : X(\vec{p}~).C^\star; \ldots; p_n : X(\vec{p}~).C^\star; C_X[\vec{q}/\vec{p}~] \fatsemi C^\star \wr \\
					&= \wr C_X[\vec{q}/\vec{p}~] \fatsemi C^\star \wr =
		\wr C_X[\vec{q}/\vec{p}~] \wr \fatsemi \wr C^\star \wr =
				\wr C_X\wr[\vec{q}/\vec{p}~] \fatsemi \wr C^\star \wr
				\end{align*}
				Using (\ref{aux:compl_wr_ih}) we construct
				$$ M^* = \mu :: \tau@p_2 :: \ldots :: \tau@p_n :: M'$$
			\item \emph{conditional} (for brevity we will only consider the \emph{true} case, the other one follows by symmetry):
				By further inversion of (\ref{aux:compl_wr_h1}) we find $C' = C_1 \fatsemi C^\star$ and $\Sigma = \Sigma'$.\\
				We now find:
				$$
				\wr C \wr = \wr~\text{if } p.e \text{ then } C_1 \text{ else } C_2;~C^\star~\wr 
				= \text{if } p.e \text{ then } \wr C_1 \wr \text{ else } \wr C_2\wr;~\wr C^\star \wr 
				$$
				Which can do a $\mu$ step and reach:
				$$ \wr C_1 \wr \fatsemi \wr C^\star \wr = \wr C_1 \fatsemi C^\star \wr = \wr C' \wr$$
				Using (\ref{aux:compl_wr_ih}) we construct $M^* = \mu :: M'$
		\end{itemize}
\end{itemize}
$\qed$

\subsubsection{Ramifications on the Semantic for Procedure Calls}
Since, as we saw in the previous section, \emph{runtime terms} are irrelevant for the computation, we will now change the semantics for CALL-FIRST to the following rule, which also makes CALL-ENTER unreachable:
$$
    \inferrule*[right=call] { X(\vec{q}~) = C \in \mathscr{C}}
	{\langle X(\vec{p}~);C', \Sigma, \mathscr{C} \rangle \xrightarrow{\cdot} \langle C[\vec{q}/\vec{p}~] \fatsemi C', \Sigma, \mathscr{C} \rangle}
$$
The correctness of this change follows from the previous proof: since both rules have as result $\wr$-equivalent configurations (we will omit a formal discussion of this equivalence) the state reached by the computation is unchanged.\\
The justification for not specifying the transition label associated with the inference rule is that we are going to mostly ignore the transition labels from now on.

\subsubsection{Completeness of the instrumented semantics}
We take a  $C, \mathscr{C}$ for which $\lceil \cdot \rceil$ is well defined.
We have to prove that, given:
$$
\langle C, \lfloor \Sigma \rfloor, \mathscr{C}\rangle \Downarrow^M \Sigma'
$$
then there exists $\Sigma''$ such that:
$$
\langle \lceil C \rceil, \Sigma, \lceil \mathscr{C}\rceil\rangle \Downarrow \Sigma''
\land \Sigma' = \lfloor \Sigma'' \rfloor 
$$


\noindent\textbf{Proof:}\\
We proceed by induction of the size of $\cdot \Downarrow^M \cdot$:
\begin{itemize}
\item \emph{size: 0}: We have 
$$ C = \boldsymbol{0} = \lceil C \rceil
\quad \text{and}\quad \lfloor \Sigma \rfloor = \Sigma'$$
so the conclusion follows with $\Sigma'' = \Sigma$
\item \emph{size: n + 1}: We have the following hypothesis:
\begin{align}
&\langle C, \lfloor \Sigma \rfloor, \mathscr{C}\rangle \xrightarrow{.}
\langle C^\star, \Sigma^\star, \mathscr{C}\rangle
\label{aux:comp_h1}\tag{H1}\\
&\langle C^\star, \Sigma^\star, \mathscr{C}\rangle
\Downarrow^\cdot \Sigma'
\label{aux:comp_h2}\tag{H2}\\
&\forall~\Sigma^\heart, \lfloor \Sigma^\heart \rfloor = \Sigma^\star
\Rightarrow \langle \lceil C^\star \rceil, \Sigma^\heart, \lceil \mathscr{C} \rceil\rangle \Downarrow \Sigma'' \land \lfloor \Sigma'' \rfloor = \Sigma'
\label{aux:comp_ih}\tag{IH}
\end{align}
We proceed by inversion on (\ref{aux:comp_h1})
\begin{itemize}
\item LOCAL: Inversion gives us:
\begin{align}
&C = p.x := e;~ C^\star \label{aux:comp_ass1}\tag{I1}\\
&\lfloor \Sigma \rfloor~p \vdash e \downarrow v \label{aux:comp_ass2}\tag{I2}\\
&\Sigma^\star = \lfloor \Sigma \rfloor[p.x \mapsto v]\label{aux:comp_ass3}\tag{I3}
\end{align}
By \emph{correctness} of the local evaluation (\ref{inst:loc_correct}) and (\ref{aux:comp_ass2}) we find:
\begin{equation}\label{aux:comp_ass4}
\Sigma~p \vdash e \downarrow [v] \quad \lor \quad
\Sigma~p \vdash e \downarrow v
\end{equation}
We proceed by cases on the hypothesis:
\begin{itemize}
\item \emph{case left:}
By definition of $\lceil \cdot \rceil$ we have:
$$\lceil C \rceil = p.x := e;~\lceil C^\star \rceil$$
We do the following execution steps:
\begin{align*}
&\langle p.x := e;~\lceil C^\star \rceil, \Sigma, \lceil \mathscr{C}\rceil\rangle\\
&\rightarrow\langle \boldsymbol{0};~\lceil C^\star \rceil, \Sigma[p.x \mapsto [v]], \lceil \mathscr{C} \rceil \rangle\\
&\rightarrow\langle \lceil C^\star \rceil, \Sigma[p.x \mapsto [v]], \lceil \mathscr{C} \rceil \rangle
\end{align*}
From which, using the fact that (equivalences on syntactic transformations are proved in Appendix \ref{appdix:A})
$$
		\lfloor\Sigma^\heart\rfloor = \lfloor \Sigma[p.x \mapsto [v]] \rfloor = \lfloor \Sigma \rfloor[p.x \mapsto v] = \Sigma^\star
$$
We can use the induction hypothesis (\ref{aux:comp_ih})
\item \emph{case right:} We have two possible rules regarding assignment with (\ref{aux:comp_ass4}) as antecedent, depending on the value of $\Gamma~p~x$. We proceed by \emph{law of excluded middle} and find:
\begin{equation}\label{aux:comp_ass5}
\Gamma~p~x \not\sqsubseteq low \quad \lor \quad
\Gamma~p~x \sqsubseteq low
\end{equation}
In the \emph{left case}, we proceed exactly as the previously specified proof case, adjusting the inference rule used for the first step. In the \emph{right case}, we follow similarly, with the only difference being:
$$
\Sigma^\heart = \Sigma[p.x\mapsto v]
$$
\end{itemize}
\item COM: The inductive case follows similarly to the LOCAL one, substituting $p.x$ with $q.x$ when needed.
\item COND-THEN: Inversion gives us:
\begin{align}
&C = \text{if } p.e \text{ then } C_1 \text{ else } C_2;~ C' \label{aux:comp_then1}\tag{I1}\\
	&C^\star = C_1 \fatsemi C'\label{aux:comp_then2}\tag{I2}\\
&\lfloor \Sigma \rfloor~p \vdash e \downarrow true \label{aux:comp_then3}\tag{I3}\\
&\Sigma^\star = \lfloor \Sigma \rfloor\label{aux:comp_then4}\tag{I4}
\end{align}
By definition of $\lceil \cdot \rceil$ we have:
$$
\lceil C\rceil = \text{if } p.e \text{ then } \lceil C_1\rceil \text{ else }\lceil C_2\rceil;~ \lceil C'\rceil
$$
We use lemma (\ref{appdix:Bfat}) on (\ref{aux:comp_ih}) and find:
$$
\langle \lceil C_1 \rceil, \Sigma, \lceil \mathscr{C} \rceil \rangle \twoheadrightarrow \langle \boldsymbol{0}, \Sigma^\dag, \lceil \mathscr{C} \rceil \rangle 
\land
\langle \lceil C' \rceil, \Sigma^\dag, \lceil \mathscr{C} \rceil \rangle \Downarrow \Sigma''
$$
Which lets us construct the following computation:
\begin{align*}
&\langle \text{if } p.e \text{ then } \lceil C_1\rceil \text{ else }\lceil C_2\rceil;~ \lceil C'\rceil, \Sigma, \lceil \mathscr{C}\rceil\rangle\\
&\rightarrow \langle \lceil C_1\rceil;~ \lceil C'\rceil, \Sigma, \lceil \mathscr{C}\rceil\rangle\\
&\twoheadrightarrow \langle \boldsymbol{0};~ \lceil C'\rceil, \Sigma^\dag, \lceil \mathscr{C} \rceil \rangle \\
&\rightarrow \langle \lceil C'\rceil, \Sigma^\dag, \lceil \mathscr{C} \rceil \rangle\Downarrow \Sigma''
\end{align*}
\item COND-ELSE: This inductive step is symmetric with respect to COND-THEN
\item CALL: Inversion gives us:
\begin{align}
&C = X(\vec{p});~ C' \label{aux:comp_call1}\tag{I1}\\
&X(\vec{q}) = C_X \in \mathscr{C} \label{aux:comp_call2}\tag{I2}\\
&C^\star = C_X[\vec{q}/\vec{p}] \fatsemi C'\label{aux:comp_then3}\tag{I3}\\
&\Sigma^\star = \lfloor \Sigma \rfloor\label{aux:comp_then4}\tag{I4}
\end{align}
By definition of $\lceil \cdot \rceil$ we have:
$$
\lceil C\rceil = X(\vec{p});~ \lceil C'\rceil
$$
We use lemma (\ref{appdix:Bfat}) on (\ref{aux:comp_ih}) and find:
$$
\langle \lceil C_X[\vec{p}/\vec{q}] \rceil, \Sigma, \lceil \mathscr{C} \rceil \rangle \twoheadrightarrow \langle \boldsymbol{0}, \Sigma^\dag, \lceil \mathscr{C} \rceil \rangle 
\land
\langle \lceil C' \rceil, \Sigma^\dag, \lceil \mathscr{C} \rceil \rangle \Downarrow \Sigma''
$$
By definition of $\lceil \mathscr{C} \rceil$, then:
$$
X(\vec{q}) = \lceil C_X \rceil \in \lceil \mathscr{C} \rceil
$$
Which lets us construct the following computation (equivalences on syntactic transformations are proved in Appendix \ref{appdix:A}):
\begin{align*}
&\langle X(\vec{p});~ \lceil C'\rceil, \Sigma, \lceil \mathscr{C}\rceil\rangle\\
&\rightarrow \langle \lceil C_X\rceil[\vec{q}/\vec{p}];~ \lceil C'\rceil, \Sigma, \lceil \mathscr{C}\rceil\rangle\\
&= \langle \lceil C_X[\vec{q}/\vec{p}]\rceil;~ \lceil C'\rceil, \Sigma, \lceil \mathscr{C}\rceil\rangle\\
&\twoheadrightarrow \langle \boldsymbol{0};~ \lceil C'\rceil, \Sigma^\dag, \lceil \mathscr{C} \rceil \rangle \\
&\rightarrow \langle \lceil C'\rceil, \Sigma^\dag, \lceil \mathscr{C} \rceil \rangle\Downarrow \Sigma''
\end{align*}
\end{itemize}
\end{itemize}
$\qed$

\subsubsection{Putting all the Steps Together}
We saw how, starting from a maximal computation
$$\langle C, \Sigma, \mathscr{C}\rangle \Downarrow^M \Sigma'$$
We can:
\begin{itemize}
\item Replace every non-deterministic aspect of the computation without changing the result, thus letting us reason only on the deterministic subset of the semantics.
\item Remove terms which do not affect the computation result, thus letting us ignore them.
\item Construct a computation in the instrumented semantics that maintains $low$-equivalence for stores.
\end{itemize}
Thus, since by definition:
$$ \lfloor \lceil \Sigma \rceil^\Gamma \rfloor = \Sigma $$
then the \emph{completeness lemma} as stated in (\ref{aux:compl}) is proven. $\qed$


\subsection{Completeness of Type Extension}\label{aux:ext_tj}
This lemma tells us that \emph{lifting} a choreography maintains typing.\\
Formally:
$$
\Delta;\Gamma;\bot \vdash C \Rightarrow
\Delta;\Gamma;\bot \vdash \lceil \wr C \wr \rceil
$$

\noindent\textbf{Proof:}\\
The type judgment is clearly maintained by $\wr \cdot \wr$ because the only effect of the operator is to \emph{remove} instructions.
The following is a more general case, easy to verify by inverting the typing rule for sequences (which is basically a \emph{conjunction}):
$$
\Delta;\Gamma;\bot \vdash I;C \Rightarrow \Delta;\Gamma;\bot \vdash C
$$
We can verify that \emph{lifting} maintains typing by noticing that $\lceil C \rceil$ never introduces a \emph{bracketed} term and for any non-bracketed term the typing rules are syntactically equivalent between \textbf{Chor} and \textbf{[Chor]}.
$\qed$

\subsection{Preservation Lemma}
The preservation lemma (i.e., subject reduction) states that the operational semantics preserves typing, that is \emph{starting from a well-typed configuration executing a step of the semantics gives us a well-typed configuration}.
We are now working only in the instrumented semantics, thus, we will omit the redundant brackets when sufficiently clear.\\
A configuration
$\langle C, \Sigma, \mathscr{C}\rangle$ is well-typed for a $pc \in \MCL$ when:
$$\Delta, \Gamma, pc \vdash C \quad \text{and}\quad \Gamma \vdash \Sigma$$
The preservation lemma is stated as follows:
\begin{equation}\label{aux:pres}
\Delta, \Gamma, pc \vdash C \land \Gamma \vdash \Sigma \land 
\langle C, \Sigma, \mathscr{C}\rangle \rightarrow
\langle C', \Sigma', \mathscr{C}\rangle \Rightarrow 
\Delta, \Gamma, pc \vdash C' \land \Gamma \vdash \Sigma'
\end{equation}
It is easy to see how the preservation lemma can be easily carried over to $\cdot \twoheadrightarrow \cdot$.

\medskip
\noindent\textbf{Proof:}\\
The majority of the preservation proof follows directly from \cite{myers2011proving}, thus, we will explain only the part which differs.\\
The main difference between our instrumented syntax and the language presented in \cite{myers2011proving} is the presence of recursive procedures.

The inductive case that we have to consider is:
\begin{align}
	&\Delta,\Gamma,pc \vdash X(\vec{p})\label{aux:pres_Htj}\tag{H1}\\
	&\langle X(\vec{p}), \Sigma, \mathscr{C}\rangle \rightarrow
	\langle C_X[\vec{q}/\vec{p}], \Sigma, \mathscr{C}\rangle\label{aux:pres_Hlto}\tag{H2}\\
	&X(\vec{q}) = C_X \in \mathscr{C}\label{aux:pres_Hlook}\tag{H3}
\end{align}
By inversion on (\ref{aux:pres_Htj}) we find:
\begin{align}
	&\Gamma' \in \Delta(X,pc) \label{aux:pres_Htj1}\tag{H11}\\
	&\Gamma[\vec{q}\mapsto \vec{p}] \equiv_{\{\vec{q}\}} \Gamma'\label{aux:pres_Htj2}\tag{H12}
\end{align}
By definition of $\Delta$, then
$$
\Gamma' \in \Delta(X,pc) \Rightarrow \Delta, \Gamma', pc \vdash C_X
$$
We now state a lemma which will not be proven in this document (since it is quite long and syntactical), but is part of the \emph{Lean} artifact.
\begin{align*}\label{aux:pres_lemma2}
\begin{split}
	\Delta, \Gamma', pc \vdash C 
	&\Rightarrow~ pn(C) \subseteq \vec{q}\\
	\Rightarrow~ \Gamma'' \equiv_{\{\vec{q}\}} \Gamma'
	&\Rightarrow~ \Delta, \Gamma'', pc \vdash C
\end{split}
\end{align*}

From \emph{well-formedness of procedure context} (assumed in \ref{ass:wellf_ctx})
we know that $pn(C_X) \subseteq \vec{q}$ thus we find
$$
\Delta,\Gamma[\vec{q}\mapsto\vec{p}],pc \vdash C_X
$$

We now introduce another lemma, proven in the \emph{Lean} code but for which the proof (for the same reasons as above) will not be reproduced in this document.\label{aux:pres_lemma1}

\begin{equation*}
\Delta, \Gamma[\vec{q}\mapsto\vec{p}], pc \vdash C \Rightarrow
\Delta, \Gamma, pc \vdash C[\vec{q}/\vec{p}]
\end{equation*}
This lemma requires \emph{freshness of formal parameters} to be proven, assumed in \ref{ass:fresh}.
We now remind ourselves the conclusion to be proven, that is:
$$
\Delta, \Gamma, pc \vdash C_X[\vec{q}/\vec{p}]\quad\land\quad \Gamma \vdash \Sigma
$$
The left-hand side is proven by the previous chain of steps.
The right-hand side is easy to prove from hypothesis of the preservation lemma.
$\qed$

\paragraph{pc subsumption:}
Subsumption of procedures invocation (used in the proof in \cite{myers2011proving} for conditional steps) is directly given by the assumption in \ref{ass:ctx_sub}

\subsection{Unwinding Lemma}
The unwinding lemma states that the operational semantics preserves low-equal configurations. We formalize this as follows.\\
Given well-typed $C_1,C_2$ in \textbf{[Chor]}, well-formed $\Sigma_1, \Sigma_2$ in \textbf{[CStore]}, then:
$$
C_1 \approx_{low} C_2 \land
\Sigma_1 \approx_{low} \Sigma_2 \land
\langle C_1, \Sigma_1, \mathscr{C} \rangle \rightarrow
\langle C_1', \Sigma_1', \mathscr{C} \rangle
$$
implies that there either exist $C_2',\Sigma_2'$ s.t.
\begin{equation}\label{aux:unw}
\langle C_2, \Sigma_2, \mathscr{C} \rangle \twoheadrightarrow
\langle C_2', \Sigma_2', \mathscr{C} \rangle
\land C_1' \approx_{low} C_2'
\land \Sigma_1' \approx_{low} \Sigma_2'
\end{equation}
or that $\langle C_2, \Sigma_2, \mathscr{C}\rangle$ diverges.

The proof of this lemma is mostly unchanged from the one presented in \cite{myers2011proving} since the differences between the two languages treated are not relevant. For this reason, we omit the proof from this document.

\section{Main Proof}
We remind ourselves the main theorem as stated in (\ref{main:def}):
\begin{align*}
	&\Delta;\Gamma;\bot \vdash C \Rightarrow
	\Sigma_1 \equiv^\Gamma_{low} \Sigma_2 \\ \Rightarrow\ &\langle C, \Sigma_1, \mathscr{C}\rangle \Downarrow^{M_1} \Sigma'_1
	\Rightarrow\ \langle C, \Sigma_2, \mathscr{C}\rangle \Downarrow^{M_2} \Sigma'_2 \\ \Rightarrow\ &\Sigma'_1 \equiv^\Gamma_{low} \Sigma'_2
\end{align*}

\noindent\textbf{Proof:}\\
By completeness (\ref{aux:compl}) we find:
$$
	\langle \lceil \wr C \wr \rceil, \lceil \Sigma_1 \rceil^\Gamma, \lceil \mathscr{C}\rceil \rangle \Downarrow [\Sigma]'_1 \quad \text{and} \quad
	\langle \lceil \wr C \wr \rceil, \lceil \Sigma_2 \rceil^\Gamma, \lceil \mathscr{C}\rceil\rangle \Downarrow [\Sigma]'_2
$$
such that
\begin{equation}\label{main:low_eq_cs}
\lfloor [\Sigma]'_1 \rfloor = \Sigma'_1 \quad \text{and} \quad
\lfloor [\Sigma]'_2 \rfloor = \Sigma'_2
\end{equation}
By extension of typing (\ref{aux:ext_tj}) we have:
$$\Delta;\Gamma;\bot \vdash \lceil \wr C \wr \rceil$$
By definition of $\lceil \cdot \rceil^\Gamma$ we have
$$
i \in {1,2} \quad \lceil \Sigma_i \rceil^\Gamma \Rightarrow
\Gamma \vdash \lceil \Sigma_i \rceil^\Gamma
$$
We can thus use preservation (\ref{aux:pres}) to find
$$
\Gamma \vdash [\Sigma]_1' \quad \text{and} \quad \Gamma \vdash [\Sigma]_2'
$$
That, with (\ref{main:low_eq_cs}) lets us reduce the proof of $
\Sigma_1' \equiv_{low}^\Gamma \Sigma_2'$ to the proof of
$ [\Sigma]_1' \approx_{low} [\Sigma]_2' $

\bigskip
\noindent We have now reduced the proof to the following:
\begin{align*}
	&\Delta;\Gamma;\bot \vdash \lceil \wr C \wr \rceil \\
	\Rightarrow\ &\langle \lceil \wr C \wr \rceil, \lceil \Sigma_1 \rceil^\Gamma, \lceil \mathscr{C} \rceil\rangle \Downarrow [\Sigma]'_1 \\
	\Rightarrow\ &\langle \lceil \wr C \wr \rceil, \lceil \Sigma_2 \rceil^\Gamma, \lceil \mathscr{C} \rceil\rangle \Downarrow [\Sigma]'_2 \\
	\Rightarrow\ &[\Sigma]'_1 \approx_{low} [\Sigma]'_2
\end{align*}
By $\Sigma_1 \equiv^\Gamma_{low} \Sigma_2$ and well-formedness of the contexts we have
$$
\lceil \Sigma_1 \rceil^\Gamma \approx_{low} \lceil \Sigma_2 \rceil^\Gamma
$$
By reflexivity of $\approx_{low}$ we have
$$
\lceil \wr C \wr \rceil \approx_{low} \lceil \wr C \wr \rceil
$$
We generalize over the specific construction of
$ \lceil \Sigma_1 \rceil^\Gamma,~\lceil \Sigma_2 \rceil^\Gamma,~\lceil \wr C \wr \rceil $ and just keep the previously stated low-equivalences between them.
At this point, the proof follows by induction on the size of $\langle \cdot, \cdot, \cdot\rangle \Downarrow [\Sigma]_1'$:
\begin{itemize}
	\item \emph{size 0}: Transition of size zero means that the first choreography is $\boldsymbol{0}$. By definition of $\approx_{low}$ the second is $\boldsymbol{0}$ aswell. By hypothesis, the two $\Sigma$ are equivalent, thus the conclusion follows.
	\item \emph{size n+1}: This means that the first transition is composed of at least one step of the operational semantics:
$$
		\langle [C]_1, [\Sigma]_1, \lceil\mathscr{C}\rceil\rangle \rightarrow
		\langle [C]_1^*, [\Sigma]_1^*, \lceil\mathscr{C}\rceil\rangle
$$
		By unwinding (\ref{aux:unw}), we find $[C_2]^*,~[\Sigma]_2^*$ s.t. the low-equivalence is respected (since we are proving \emph{termination insensitive non-interference}, we have as hypothesis that the computation from $\langle [C]_2, [\Sigma]_2, \lceil\mathscr{C}\rceil\rangle$ does not diverge).
		By preservation (\ref{aux:pres}), we find well-typedness and well-formedness needed to use the induction hypothesis, from which we prove the conclusion.
\end{itemize}
$\qed$

\chapter{Construction of $\Delta$}\label{chap:delta}
We now deal with the creation of the \textbf{SecFunCtx} from a \emph{well-formed procedure context} (as defined in \ref{ass:wellf_ctx}).

Let us remind ourselves the properties which we previously assumed for $\Delta$:
\begin{itemize}
\item \emph{Well-typedness with respect to $\mathscr{C}$}: As defined in \ref{ass:wellt_ctx}, we want
$$
\Delta~X~pc = \mathcal{G}
\;\Longrightarrow\;
\forall\,\Gamma \in \mathcal{G}.\ \Delta;\Gamma;pc \vdash C
$$
This property can be stated as follows: every declared procedure must typecheck under every security environment that \(\Delta\) admits for it (at any program counter). It is to be noted that the lookup yields an empty set of admissible environments in the case of untypable procedure at a certain $pc$ i.e., \(\Delta~X~pc=\varnothing\).
\item \emph{pc subsumption of context}: For any procedure in $\Delta$, we want the typing to be maintained when lowering the control level, defined formally in \ref{ass:ctx_sub} as:
$$
  \Gamma \in \Delta~X~pc\ \wedge\ pc' \sqsubseteq pc
  \ \Longrightarrow\
  \Gamma \in \Delta~X~pc'
$$
\end{itemize}
Those are the two properties assumed as true and used for the previous proof of non-interference. In the following sections, we will take ideas and terminology from the practice of \emph{type reconstruction}\cite{pierce2002types}.

\section{Context Reconstruction Algorithm}
The key idea behind constructing $\Delta$ is inferring from every function $X(\vec{q}) = C_X$ in $\mathscr{C}$ a list of \emph{constraints} such that, if $\Gamma$ satisfies those constraints, then it well-types $C_X$.

\subsection{Local Expression Reconstruction}
Let us start dealing with local expressions. The idea here is to infer a symbolic \emph{bound} which can delay the computation of the security level of an expression. We define the following syntax:
$$
\uppsi ::= \bot \mid x \mid \uppsi \sqcup \uppsi
$$
Where $\bot$ is an arbitrary symbol and $x$ is taken from the previously defined set \textbf{Var}. We define \textbf{ExprBound} as the set of the objects generated by the nonterminal $\uppsi$.\\
We associate a \emph{semantics} to the syntactic category \textbf{ExprBound}:
$$\llbracket \uppsi \rrbracket: \textbf{SecPLab} \rightarrow \MCL$$
That is, the semantics of a bound is defined as a map that computes the level associated with a local expression given an security level assignment for the variables present. We define it recursively on the structure of $\uppsi$:
\begin{align*}
\llbracket \bot \rrbracket~\gamma &= \bot\\
\llbracket x \rrbracket~\gamma &= \gamma~x\\
\llbracket \uppsi_1 \sqcup \uppsi_2 \rrbracket~\gamma &= (\llbracket \uppsi_1 \rrbracket~\gamma) \sqcup (\llbracket \uppsi_2 \rrbracket~\gamma)
\end{align*}

We now define the procedure of bound reconstruction $\vdash e \rhd \uppsi$ that, given an \textbf{Expr} $e$, returns the associated bound:
\begin{mathpar}
\inferrule{}{ \vdash v \rhd \bot }
\and
\inferrule{}{ \vdash x \rhd x }
\and
\inferrule{
  \sigma \vdash e_1 \rhd \uppsi_1 \quad \cdots \quad \sigma \vdash e_n \rhd \uppsi_n
}{
\sigma \vdash f(e_1,\ldots,e_n) \rhd \sqcup^n_{i=1} \uppsi_i
}
\end{mathpar}

We now state and prove the \emph{correctness} of this algorithm with respect to the typing relation for \textbf{Expr} previously defined. Formally:
\begin{equation}\label{rec:expr_corr}
\vdash e \rhd \uppsi~\land~\llbracket \uppsi \rrbracket~\gamma = \ell~\Longrightarrow~\gamma \vdash e: \ell
\end{equation}

\noindent\textbf{Proof:}\\
We proceed by induction on $e$
\begin{itemize}
\item \emph{constant:} we have the following:
$$
e=v\quad\uppsi=\bot\quad\ell=\bot
$$
The conclusion comes easily from the corresponding typing rule in \ref{typ_def:expr}.
\item \emph{variable:} we have the following:
$$
e=x\quad\uppsi=\gamma~x\quad\ell=\gamma~x
$$
The conclusion comes easily from the corresponding typing rule in \ref{typ_def:expr}.
\item \emph{local function:} We have the following:
\begin{align}
&e=f(e_1, \ldots, e_n)\quad\uppsi=\sqcup^n_{i=1}\uppsi_i
\quad \ell= \llbracket\sqcup^n_{i=1}\uppsi_i \rrbracket~\gamma \tag{H1}\\
&\llbracket \uppsi_i \rrbracket = \ell_i \Rightarrow \gamma \vdash e_i:\ell_i\tag{IH}
\end{align}
By definition of $\llbracket \cdot \rrbracket$ and (H1) we find:
$$
\ell_i = \llbracket \uppsi_i\rrbracket~\gamma \quad\quad \ell = \sqcup^n_{i=1}\ell_i
$$
Which can be used with (IH) to construct the typing derivation for:
$$
\gamma \vdash f(e_1, \ldots, e_n) : \ell
$$
\end{itemize}
$\qed$

\subsection{Choreography Reconstruction}
The main idea remains the same as before.
We firstly define the syntactic category \textbf{Bound}:
$$
\Uppsi ::= \bot \mid p.x \mid \eta \mid \Uppsi \sqcup \Uppsi
$$
where $p.x \in \textbf{Pid} \times \textbf{Var}$, $\eta$ taken from a set \textbf{Fresh} of variables \emph{always considered sufficiently fresh}. $\eta$ will represent the security level of $pc$ in bounds.

\noindent We define the syntactic category \textbf{Constraint} (the name is self-explanatory):
$$
\omega ::= \Uppsi \sqsubseteq p.x
$$
We define a \emph{constraint context} (\textbf{ProcConstr}) $\delta: \textbf{ProcName} \rightarrow \textbf{Finset Constraint}$ which maps every procedure to the associated finite set of constraints.\\
We can now define the constraint reconstruction procedure $\delta, \eta\vdash C\rhd\Uppsi$ as follows:
$$
\inferrule{\vdash e \rhd \uppsi_e\quad\Uppsi_p =\text{bind }\uppsi_e~p}
{\delta, \eta \vdash p.x := e \rhd \{\Uppsi_p \sqsubseteq p.x, \eta \sqsubseteq p.x\}}
$$
$$
\inferrule{\vdash e \rhd \uppsi_e\quad\Uppsi_p =\text{bind }\uppsi_e~p}
{\delta, \eta \vdash p.e \rightarrow q.x \rhd \{\Uppsi_p \sqsubseteq q.x, \eta \sqsubseteq q.x\}}
$$
$$
\inferrule{\vdash e \rhd \uppsi_e\quad\Uppsi_p =\text{bind }\uppsi_e~p\quad \delta,\eta_1'\vdash C_1 \rhd E_1 \quad \delta,\eta_2'\vdash C_2 \rhd E_2}
{\delta, \eta \vdash \text{if } p.e \text{ then } C_1 \text{ else } C_2 \rhd E_1[\eta_1' / \eta \sqcup \Uppsi_p] \cup E_2[\eta_2' / \eta \sqcup \Uppsi_p]}
$$
$$
\inferrule{\delta~X = \vec{q}, \eta_X, E_X}
{\delta, \eta \vdash X(\vec{p}) \rhd E_X[\vec{q}/\vec{p}][\eta_X/\eta]}
$$
$$
\inferrule{\delta, \eta \vdash I \rhd E_I \quad \delta, \eta \vdash C \rhd E_C}
{\delta, \eta \vdash I; C \rhd E_I \cup E_C}
$$
$$
\inferrule{}{\delta, \eta \vdash \boldsymbol{0} \rhd \emptyset}
$$
Substitution in a constraint set is defined naturally.\\
The function bind is defined as \emph{lifting} an \textbf{ExprBound} into a \textbf{Bound} by binding every \textbf{Var} into the corresponding $\textbf{Pid} \times \textbf{Var}$

We can already state a first lemma, which will be useful in the following:\\
\textbf{Single eta}: For each constraint reconstruction $E$ such that:
$$
\delta, \eta \vdash C \rhd E
$$
Then, the only element of \textbf{Fresh} that can appear in $E$ is $\eta$, given that this property is respected for every $\eta_X, E_X$ in $\delta$. It is to be noted that it is admitted for $E$ to have no element of \textbf{Fresh}.

\noindent\textbf{Proof:} The proof easily follows by induction. $\qed$

We now define a couple of functions that relate constraints with security contexts:
\begin{align*}
\text{\underline{cansolve}}~&(E: \textbf{Finset Constraint})~(\Gamma: \textbf{SecCLab})~(pc: \MCL): \textbf{Proc} :=\\
&\forall~(\Uppsi \sqsubseteq p.x) \in E,~\llbracket \Uppsi \rrbracket~\Gamma~pc \sqsubseteq \Gamma~p.x
\end{align*}
Where $\llbracket \cdot\rrbracket$ for \textbf{Bound} is the natural extension from the one for \textbf{ExprBound}.
\begin{align*}
\text{\underline{gen}}~&(\delta: \textbf{ProcConstr}): \textbf{ProcName} \rightarrow \MCL \rightarrow \textbf{Finset SecCLab} :=\\
&\lambda~X.~\lambda~pc.~\{ \Gamma \mid \text{\underline{cansolve}}~(\delta~X)~\Gamma~pc\}
\end{align*}

\section{Proof of Well-Typedness}
We are looking to prove that given a $\mathscr{C}$ we can use the type reconstruction algorithm to create a $\delta$ such that $\text{\underline{gen}} ~\delta$ creates a \emph{well-typed context} (\ref{ass:wellt_ctx}) with respect to $\mathscr{C}$.

\subsection{Creating $\delta$}
We start by defining a monotonic operator $\upphi_\mathscr{C}: \textbf{ProcConstr} \rightarrow \textbf{ProcConstr}$ as follows:
$$
\upphi_\mathscr{C}: \delta \mapsto (X \mapsto E_X)
$$
Where $X(\vec{q}) = C_X \in \mathscr{C}$ and $E_X$ is computed as $\delta, \eta\vdash C_X \rhd E_X$\\
$\upphi_\mathscr{C}$ creates a delta by applying \emph{one pass} of constraint reconstruction to every procedure in the procedure context. This is needed because procedures can be mutually recursive, thus, we need multiple passes to construct all constraints correctly. Proof of monotonicity of $\upphi_\mathscr{C}$ is addressed in Appendix \ref{appdix:rec:monotono}.
\subsection{One step soundness}
We proceed by stating and proving the following:
\begin{align}
\begin{split}\label{rec:one_step}
&\Delta = \text{\underline{gen}}~\delta\\
&\Rightarrow \delta, \eta \vdash C \rhd E\\
&\Rightarrow \text{\underline{cansolve}}~E~\Gamma~pc\\
&\Rightarrow \Delta, \Gamma, pc \vdash C
\end{split}
\end{align}

\noindent\textbf{Proof:}
We proceed by induction on $C$
\begin{itemize}
\item\emph{case: assignment.} By inversion and unrolling the definition of \underline{cansolve} we have the following hypothesis:
\begin{align}
&\vdash e \rhd \uppsi_e \tag{H1}\\
&\Uppsi_p =~\text{bind}~\uppsi_e~p\tag{H2}\\
&\llbracket \Uppsi_p\rrbracket~\Gamma~pc \sqsubseteq \Gamma~p.x\tag{H3}\\
&\llbracket \eta\rrbracket~\Gamma~pc \sqsubseteq \Gamma~p.x \tag{H4}
\end{align}
We start by constructing:
$$
\ell = \llbracket \uppsi_e \rrbracket~(\Gamma~p)
$$
By hypothesis (H1) and lemma (\ref{rec:expr_corr}) we find:
$$
\Gamma~p\vdash e:\ell
$$
By (H2) and definition of $\llbracket \cdot \rrbracket$ we find:
$$
\ell = \llbracket \Uppsi_p \rrbracket~\Gamma~pc
\quad\quad pc = \llbracket \eta \rrbracket~\Gamma~pc
$$
By (H3) and (H4) we thus find the premise necessary for typing
$$
\Delta, \Gamma, pc \vdash p.x := e
$$

\item\emph{case: communication.} The case follows similarly from the previous one
\item\emph{case: conditional.} We have the following hypothesis:
\begin{align}
&\vdash e \rhd \uppsi_e \tag{H1}\\
&\Uppsi_p =~\text{bind}~\uppsi_e~p\tag{H2}\\
&\delta, \eta_1' \vdash C_1 \rhd E_1 \tag{H3}\\
&\delta, \eta_2' \vdash C_2 \rhd E_2 \tag{H4}\\
&\text{\underline{cansolve}}~(E_1[\eta/\eta_1' \sqcup \Uppsi_p] ~\cup~ E_2[\eta/\eta_2' \sqcup \Uppsi_p])~\Gamma~pc \tag{H5}\\
\forall~pc^\star,~&\text{\underline{cansolve}}~E_1~\Gamma~pc^\star \Rightarrow \Delta, \Gamma, pc^\star \vdash C_1 \tag{IH1}\\
\forall~pc^\star,~&\text{\underline{cansolve}}~E_2~\Gamma~pc^\star \Rightarrow \Delta, \Gamma, pc^\star \vdash C_2 \tag{IH2}
\end{align}
As before, we can use (H1), lemma (\ref{rec:expr_corr}) and (H2) to find:
$$
\ell = \llbracket \uppsi_e \rrbracket~(\Gamma~p)~~(\text{A1})
\quad\quad
\Gamma~p\vdash e:\ell
\quad\quad
\ell = \llbracket \Uppsi_p \rrbracket~\Gamma~pc
$$
We will now concentrate ourself to the typing of the \emph{then} branch, since the other one follows by symmetry.\\
By reasoning on the definition of \underline{cansolve} and (H5) we find:
$$
\text{\underline{cansolve}}~E_1[\eta/\eta_1' \sqcup \Uppsi_p]~\Gamma~pc
$$
We now apply the following lemma (proved in Appendix \ref{appdix:rec:cansolve_pc})
\begin{align*}
&\text{\underline{cansolve}}~E[\eta/\eta' \sqcup \Uppsi]~\Gamma~pc
\quad\land\quad (\forall pc', \llbracket \Uppsi \rrbracket~\Gamma~pc'=\ell')\\
&\Longrightarrow \text{\underline{cansolve}}~E~\Gamma~(pc\sqcup\ell')
\end{align*}
We see how the second premise is true for the considered $\ell$: no $pc$ appears in (A1).\\
We thus use (IH1) to find the required typing:
$$
\Delta, \Gamma, (pc \sqcup \ell) \vdash C_1
$$
\item\emph{case: procedure call.} We have the following hypothesis:
\begin{align*}
	&\Delta = \text{\underline{gen}}~\delta\tag{H1}\\
	&\delta~X = \vec{q}, \eta_X, E_X \tag{H2}\\
	&\text{\underline{cansolve}}~E_X[\vec{q}/\vec{p}~][\eta_X/\eta]~\Gamma~pc\tag{H3}
\end{align*}
We introduce the following lemmas: the first one follows from \emph{Single eta} and the second one is proven in Appendix \ref{appdix:rec:cansolve_sub}:
\begin{align*}
\text{\underline{cansolve}}~E[\eta/\eta']~\Gamma~pc
&\Rightarrow \text{\underline{cansolve}}~E~\Gamma~pc\\
\text{\underline{cansolve}}~E[\vec{q}/\vec{p}~]~\Gamma~pc
&\Rightarrow \text{\underline{cansolve}}~E~\Gamma[\vec{q}\mapsto\vec{p}~]~pc
\end{align*}
We apply these lemmas to (H3), which gives us:
$$
\text{\underline{cansolve}}~E_X~\Gamma[\vec{q}\mapsto\vec{p}~]~pc
$$
From (H2), (H1) and the definition of \underline{gen} we get:
$$
\Gamma[\vec{q}\mapsto\vec{p}~] \in \Delta~X~pc
$$
Thus we can use the typing rule for procedure calls, selecting $\Gamma' = \Gamma[\vec{q}\mapsto\vec{p}]$. By reflexivity, is it trivial to show:
$$
\Gamma[\vec{q}\mapsto\vec{p}] \equiv_{\{\vec{q}\}} 
\Gamma[\vec{q}\mapsto\vec{p}]
$$
\end{itemize}
$\qed$
\subsection{Well-Typed $\delta$}
By our definition, \textbf{ProcConstr} can be considered as finite, this holds because we are working with a finite $\MCL$ and because the number of procedure names mentioned in a finite choreography is always finite.
By Knaster-Tarski theorem\cite{tarski1955lattice}, there exists a \emph{least fixed point} for $\upphi_\mathscr{C}$. Let us now reason on the previous results:\\
A trivial lemma of \ref{rec:one_step} is the following:
\begin{align*}
&\Delta = \text{\underline{gen}}~\delta_1\\
&\Rightarrow \delta_2 = \upphi_\mathscr{C}~\delta_1\\
&\Rightarrow \text{\underline{cansolve}}~(\delta_2~X)~\Gamma~pc\\
&\Rightarrow \Delta,\Gamma,pc \vdash C_X
\end{align*}
We can thus see that, choosing as $\delta_1$, a fixed point $\mu\upphi_\mathscr{C}$, and by using the definition of \underline{gen}, this lemma becomes:
\begin{align*}
&\Delta = \text{\underline{gen}}~\mu\upphi_\mathscr{C}\\
&\Rightarrow \Gamma~\in~\Delta~X~pc\\
&\Rightarrow \Delta,\Gamma,pc \vdash C_X
\end{align*}
Which makes $\Delta$ a \emph{well-typed security procedure context}. $\qed$

\section{Proof of pc Subsumption}
We remind ourselves the statement of pc subsumption for contexts:
$$
\Delta = \text{\underline{gen}}~\delta~\land~\Gamma\in\Delta ~X~pc~\land~pc' \sqsubseteq pc \Longrightarrow \Gamma \in \Delta~X~pc'
$$

\noindent\textbf{Proof:}
By definition of \underline{gen} we can rewrite the statement as follows:
$$
\text{\underline{cansolve}}~E~\Gamma~pc
~\land~pc'\sqsubseteq pc~\Longrightarrow
\text{\underline{cansolve}}~E~\Gamma~pc'
$$
Which we can further decompose by unfolding the definition of \underline{cansolve} into:
$$
\llbracket \Uppsi\rrbracket~\Gamma~pc\sqsubseteq p.x\land~pc'\sqsubseteq pc\Longrightarrow \llbracket \Uppsi\rrbracket~\Gamma~pc'\sqsubseteq p.x
$$
Which becomes:
$$
pc'\sqsubseteq pc\Longrightarrow \llbracket \Uppsi\rrbracket~\Gamma~pc'\sqsubseteq \llbracket\Uppsi\rrbracket~\Gamma~pc
$$
Which is easily proven reasoning inductively on the structure of $\Uppsi$.$\qed$

\section{Termination}
Since all the operations functions defined work on finite structures, there will always be a terminating algorithm to compute them.

\section{Extension to Full Type Inference}
The algorithm we defined is very similar to type-inference\cite{pierce2002types}, but a few aspects need to be treated formally to consider it so. Let us now give an overview of the main ones.
\begin{itemize}
\item \emph{Reconstruction of constraints for the configuration's choreography}. This should not be any harder than to reconstruct constraints from the procedure context. A way forward would be to consider the configuration's choreography as an \emph{unnamed} procedure inside the context.
\item \emph{Proof of completeness of the constraint reconstruction algorithm with respect to the type checking}. This requires creating an order relation on the \textbf{Constraint} set, such that it is possible to define a \emph{minimal} set of constraints. Afterwards, the proof would follow by proving that every $\Gamma$ typing a choreography would satisfy the minimal set of constraints reconstructed for that choreography.
\end{itemize}
We do not address these topics in this thesis because of the limited time available.

\chapter{Lean mechanization}
\noindent
In this chapter we present the mechanization in \emph{Lean 4} of the type system and meta-theory developed in the previous chapters for choreographic programs. We begin by fixing the notational conventions used in the formalization. We then describe the external foundations we rely on. Next, we outline the structure of the project and the role of each file, highlighting the main design choices behind the core definitions: syntax, semantics, typing and the lowering/lifting translations. We also clarify the coverage of the mechanization, stating which results are fully checked in Lean and which parts remain admitted together with the rationale. Finally, we work through a representative lemma to illustrate the proof style.

\label{chap:lean}
\section{Naming Conventions}
In the following, a few naming conventions are different and should be considered:
\begin{align*}
\texttt{L} &\triangleq \MCL &\texttt{ps} &\triangleq \vec{p}\\
\texttt{D} &\triangleq \Delta & \texttt{G} &\triangleq \Gamma\\
\texttt{BrChor} &\triangleq \textbf{[Chor]}
\end{align*}

\section{Imported Definitions and Results}
\label{lean:imports}
\subsection{Encoding of $\MCL$}
\emph{Mathlib 4}\cite{mathlib4} was used as library in the project. This was done so that we could take advantage of the already mechanized math results.\\
The biggest contribution taken from the library is the \texttt{Mathlib.Order.Lattice} module, which was used to encode $\MCL$ by defining it as a \emph{type variable} which implements the \texttt{Lattice}, \texttt{DecidableLE} and \texttt{Bot} \emph{type classes}.
\subsection{Reference choreographies}
Ongoing research is being done by Xueying Qin and Fabrizio Montesi at SDU to mechanize the language defined in Section \ref{background:choreographies}.
My work builds on theirs, importing the needed definitions and results. The main imported constructs are: procedure context implementation and the syntax and semantics for reference choreographies.

\section{Project Structure}
The project is divided into multiple files to deal with the length and complexity of the proof. These files are the following:
\begin{itemize}
	\item \texttt{Common.lean} This file contains all the definitions which are needed by all the other files in the project. For example \emph{security labeling} (Section \ref{type:flow-policy}):
\begin{samepage}
\begin{verbatim}
-- Security Labeling for Variables of a Processes
abbrev SecPLab := Var -> L
-- Security Labeling for Variables "Globally"
abbrev SecCLab := Pid -> @SecPLab L
\end{verbatim}
\end{samepage}
Or \emph{security context for procedures}:
\begin{samepage}
\begin{verbatim}
def SecFunCtx :=
    ProcName -> L -> (List Pid x Finset (@SecCLab L))
\end{verbatim}
\end{samepage}

\item \texttt{Syntax.lean} This file contains the definition of the instrumented syntax, encoded as an inductive type, and all related lemmas and definition (for example \emph{substitution}, \emph{low equality}).

\item \texttt{Semantics.lean} This file contains both the natural semantics as defined in Section \ref{nat_sem} and the operational semantics for instrumented choreographies. Both relations are defined as inductive types. Let us see the signatures for them:
\begin{samepage}
\begin{verbatim}
inductive Chor.natsem {sig: EvalSig}:
    CConf -> List TransitionLabel -> CStore -> Prop

inductive BrChor.lto {G: @SecCLab L}:
    BrConf -> BrConf -> Prop
\end{verbatim}
\end{samepage}
\item \texttt{Typing.lean} This file contains the typing relation as defined in Section \ref{type:formal} and all the helper lemmas used in the proofs. The relation is encoded as an mutually inductive type, with the following signature:
\begin{samepage}
\begin{verbatim}
mutual
inductive tj_i {D: @SecFunCtx L} {G: @SecCLab L}:
    L -> Instruction -> Prop

inductive tj_c {D: @SecFunCtx L} {G: @SecCLab L}:
    L -> Choreography -> Prop
end
\end{verbatim}
\end{samepage}
\item \texttt{LowerLiftStx.lean} In this file are defined and mechanized all the lowering/lifting functions which this document treated at a more abstract level. A great deal of helper and inversion lemmas are needed to make the definitions usable in the proofs. To cite some numbers, the file is composed of 1389 lines of code for 8 lowering/lifting functions. Let us see a few cases of the lifting function for choreography, to see how the issue of $\wr \cdot \wr$ was dealt with:
\begin{samepage}
\begin{verbatim}
mutual
def lift_i (i: Instruction) (H1: no_choice_i i)
    (H2: no_rtcall_i i): BrChor := match i with
    | Instruction.assign p e x => BrChor.ass p e x
    | Instruction.cond p e c1 c2 => BrChor.cond p e
        (lift_c c1 (...) (...))
        (lift_c c2 (...) (by dsimp [no_rtcall_i] at H2;
                             apply And.right H2))
    | Instruction.rtcall q x ps c => (by exfalso; apply H2)

def lift_c (c: Choreography) (H1: no_choice_c c)
    (H2: no_rtcall_c c): BrChor := match c with
    | Choreography.nil => BrChor.nil
    | Choreography.seq i c' => BrChor.seq
        (lift_i i (...) (...))
        (lift_c c' (...) (by dsimp [no_rtcall_c] at H2;
                             apply And.right H2))
end
\end{verbatim}
\end{samepage}
Where \texttt{no\_rtcall} is defined as follows (in file \texttt{Common.lean}):
\begin{samepage}
\begin{verbatim}
mutual
def no_rtcall_i (i: Instruction): Prop := match i with
    | Instruction.rtcall _ _ _ _ => False
    | Instruction.cond _ _ c1 c2 => no_rtcall_c c1 /\ no_rtcall_c c2
    | _ => True

def no_rtcall_c (c: Choreography): Prop := match c with
    | Choreography.nil => True
    | Choreography.seq i c' => no_rtcall_i i /\ no_rtcall_c c'
end
\end{verbatim}
\end{samepage}
\item \texttt{Completeness.lean} The main theorem defined in this file is (\ref{aux:compl}). I was not able to finish the proof in Lean for lack of time. Since the completeness proof is not mechanized, it was described in deeper detail in this document.
\item \texttt{Preservation.lean} The main theorem proved in this file is \ref{aux:pres}. In the same file are defined and proved helper lemmas (for example \emph{pc subsumption} and typing for instrumented local expressions).
\item \texttt{Unwinding.lean} The main theorem proved in this file is \ref{aux:unw}. In the same file are defined and proved helper lemmas (for example the \emph{high step lemma}\cite{myers2011proving} and helper lemmas for low equality of instrumented stores).
\item \texttt{NonInt.lean} This file contains the main proof, corresponding to \ref{main:def}.
All the other files of the project are imported in this one to be able to define and prove the main theorem.
\end{itemize}

\section{Coverage of the Mechanization}
Many results described in this document have been mechanized and are present in the Lean code, but not all.
Two main results are admitted and are proved only by pen-and-paper: \emph{completeness of the reference semantics with respect to the instrumented semantics} and \emph{construction of $\Delta$}.\\
These two sections were not represented in Lean for time constraints: any non-trivial lemma requires me to have first a pen-and-paper presentation. This is because, while writing Lean code, it is very easy to concentrate on the syntactical aspects of the proof and to lose sight of the overall strategy.
Moreover, once the proof strategy is clear, the process of encoding it in Lean can be very time consuming, and it is sometimes difficult to correctly predict which proof steps are going to be the most challenging. Sometimes, half a page paper presentations become hundreds and hundreds of lines of code.

\section{An Illustrative Example}
We will now show the Lean implementation of the following lemma, used in Section \ref{aux:pres_lemma1}. Let us remind ourselves the lemma statement:
\begin{equation*}
\Delta, \Gamma[\vec{q}\mapsto\vec{p}~], pc \vdash C \Longrightarrow
\Delta, \Gamma, pc \vdash C[\vec{q}/\vec{p}~]
\end{equation*}
In Lean, the same statement is expressed as:
\begin{samepage}
\begin{verbatim}
def tj_substs {D: @SecFunCtx L} {G: SecCLab} {pc: L} {c: BrChor}
    {ps qs: List Pid} {Hlen: ps.length = qs.length}:
    fresh_functx D
    -> @tj_bc _ _ low tjeval D (secclab_substs G ps qs Hlen) pc c
    -> @tj_bc _ _ low tjeval D G pc (c.substitutions ps qs Hlen)
\end{verbatim}
\end{samepage}
As we can see, most of the assumptions which are treated as implicit in the pen-and-paper proof, here, need to be made explicit.
\begin{itemize}
\item \emph{Same length of $\vec{p}$ and $\vec{q}$}: In this document, we always assumed same lenght from the arguments of every substitution operation. Let us now see how the substitution is defined in the Lean code:
\begin{verbatim}
def BrChor.substitutions (c: BrChor) (ps qs: List Pid)
    (H: ps.length = qs.length): BrChor :=
        match ps, qs with
        | hp::tp, hq::tq =>
            BrChor.substitutions (c.substitution hp hq) tp tq
                (by simp_all)
        | [], [] => c
\end{verbatim}
Where \texttt{BrChor.substitutions} performs \textbf{Pid} substitution for choreographies as defined in Section \ref{intro:chor_subst}.
We see how the function is only defined for inputs of the same length, and how this requirement allows us to ignore the impossible pattern matching cases.

\item \emph{Fresh parameters for $\Delta$}:
We want to encode the assumption \emph{freshness of formal parameters} as defined in Section \ref{ass:fresh}.
\begin{verbatim}
def fresh_functx (D: @SecFunCtx L) :=
    forall (pc: L) (X: ProcName) (qs: List Pid) (ps: Finset Pid),
    qs = Prod.fst (D X pc) -> Disjoint ps qs.toFinset
\end{verbatim}
We note how this property is too restricting, since it can be used with $qs = ps$ to prove that every procedure has an empty list of arguments. While this is technically incorrect, it is a necessary requirement for the semantics as specified in Section \ref{lean:imports} (which were, thus, outside of my control). A cleaner solution would be to define $\mathscr{C}$ as a \emph{partial} function with a finite image, such that we can enforce a partitioning of the set \textbf{Pid} between the procedures and the \emph{main} choreography.
\end{itemize}
\subsubsection{Context Renaming}
We now see how the function \texttt{secclab\_substs} encodes the \emph{context renaming} operator as defined in Section \ref{def:context_renaming}. The function is defined as follows:
\begin{samepage}
\begin{verbatim}
def secclab_substs (G: @SecCLab L) (p q: List Pid)
    (h: p.length = q.length): @SecCLab L := match p, q with
       | hp::tp, hq::tq =>
            secclab_subst (secclab_substs G tp tq
                (by simp only 
                    [List.length_cons, add_left_inj] at h
                 apply h))
            hp hq
       | [], [] => G
\end{verbatim}
\end{samepage}
Where \texttt{secclab\_subst} is the function dealing with scalar substitution, defined as follows:
\begin{samepage}
\begin{verbatim}
def secclab_subst (G: @SecCLab L) (p q: Pid): @SecCLab L :=
    lambda r => if p = r then G q else G r
\end{verbatim}
\end{samepage}

\subsubsection{Proof}
For the rest of the chapter there is an important note to make: my proof style in Lean can be considered mostly \emph{backward chaining}\cite{al2015comparison}, that is, I tend to manipulate the goal more than the hypothesis.
Let us now see the proof body in Lean, omitting the uninteresting induction cases.
\begin{samepage}
\begin{verbatim}
    intro Hfresh H1
    induction H1
    case tass l' Htjeval Hsub =>
        rw [BrChor.substitutions.inversion_ass]
        apply tj_bc.tass (l' := l')
        case a => simp_all [sec_substs_of_pid_substs]
        case a => simp_all [sec_substs_of_pid_substs]
    case tcond Heval _ _ IH1 IH2 =>
        rw [BrChor.substitutions.inversion_cond]
        rw [sec_substs_of_pid_substs (G := G)] at Heval
        apply tj_bc.tcond Heval IH1 IH2
    case tcall G' pc x ps' qs' Hlen Hg Hqs Hgam =>
        rw [BrChor.substitutions.inversion_call]
        dsimp [fresh_functx] at Hfresh
        apply tj_bc.tcall Hg Hqs
        have Hdis1 := Disjoint.symm
            (Hfresh pc x qs' ps'.toFinset Hqs)
        have Hdis3 := Disjoint.symm (Hfresh pc x qs' qs.toFinset Hqs)
        apply gam_res_eq_trans
        apply (gam_res_eq_symm (gamsubsts_helper Hdis1 Hdis3))
        apply Hlen
        apply Eq.trans Hlen pids_substs_length
        apply Hgam
\end{verbatim}
\end{samepage}
Let us unpack what happens in this code snippet. The proof follows by induction on the typing derivation \texttt{tj\_bc}. We will explain the cases for \emph{assignment}, \emph{conditionals}, and \emph{procedure calls}.
\begin{itemize}
\item \emph{assignment}: The inductive cases gives us hypothesis for the typing of the expression (\texttt{Htjeval}) and on the order relation between $\ell$ and $\Gamma~p~x$ (\texttt{Hsub}).\\
The first step rewrites the goal from:\\
\texttt{tj\_bc D G pc ((BrChor.ass p e x).substitutions ps qs Hlen)}\\
to \texttt{tj\_bc D G pc (BrChor.ass (pid\_substs p ps qs Hlen) e x)}.
Thus, enabling us to use the typing rule for assignments.
The two assumptions of the typing rule are discharged by the proof search mechanism of Lean, using the following helper lemma (which is used on \texttt{Heval} to make it compatible with the needed assumption):
\begin{verbatim}
lemma sec_substs_of_pid_substs {G: @SecCLab L}
    {r: Pid} {ps qs: List Pid} {Hlen}:
    (secclab_substs G ps qs Hlen) r = G (pid_substs r ps qs Hlen)
\end{verbatim}
\item \emph{conditional}: The inductive case gives us the hypothesis for the typing of the expression (\texttt{Heval}), and two inductive hypotheses for the two branches (\texttt{IH1,  IH2}).
The typing of the expression is dealt with exactly as in the previous case, but to be able to use the typing rule on the goal we need to apply the inductive hypothesis.
\item \emph{procedure call}: We first, as we did in the previous inductive cases, invert the process substitution to be able to use the call typing rule. The function lookup part of the typing derivation remains the same (which finds $\Gamma', \vec{r}$), thus it remains to prove the following:
$$
\Gamma' \equiv_L \Gamma[\vec{q} \mapsto \vec{p}~][\vec{r} \mapsto \vec{s}]
\Longrightarrow 
\Gamma' \equiv_L \Gamma[\vec{q} \mapsto \vec{p}~[\vec{r}/\vec{s}]]
$$
From the freshness of the procedure parameters we have that
$$\vec{r} \cap (\vec{q} ~\cup ~\vec{p}~) = \emptyset$$
And from the fact that $\equiv_L$ is an equivalence relation, we can reduce the goal to
\begin{align*}
&\vec{r} \cap \vec{q} = \emptyset\\
&\Longrightarrow \vec{r} \cap \vec{p} = \emptyset\\
&\Longrightarrow \Gamma[\vec{q} \mapsto \vec{p}~][\vec{r} \mapsto \vec{s}]
\equiv_L \Gamma[\vec{q} \mapsto \vec{p}~[\vec{r}/\vec{s}]]
\end{align*}
Which is proven by the lemma \texttt{gamsubsts\_helper}, as can be seen by its signature:
\begin{samepage}
\begin{verbatim}
lemma gamsubsts_helper {ps qs rs ss: List Pid}
    {G: @SecCLab L} {Hlen1 Hlen2 Hlen3}:
    Disjoint ss.toFinset rs.toFinset
    -> Disjoint ss.toFinset qs.toFinset
    -> gam_res_eq ss.toFinset
        (secclab_substs
            (secclab_substs G ps qs Hlen1) ss rs Hlen2)
        (secclab_substs G ss (pids_substs rs ps qs Hlen1) Hlen3)
\end{verbatim}
\end{samepage}
The proof of this lemma will be described in the next section.
\end{itemize}
$\qed$

\subsubsection{Proof of \texttt{gamsubsts\_helper}}
To understand it, we need to detail two more definitions:
\begin{samepage}
\begin{verbatim}
def gam_res_eq (ps: Finset Pid) (g1 g2: @SecCLab L): Prop :=
    forall (p: Pid), p in ps -> g1 p = g2 p

def Pid.substitution (p r s: Pid): Pid :=
  if p = r then s else p

def pid_substs (r: Pid) (ps qs: List Pid)
    (H: ps.length = qs.length): Pid :=
    match ps, qs with
    | hp::tp, hq::tq =>
        pid_substs (r.substitution hp hq) tp tq (by simp_all)
    | [], [] => r

def pids_substs (rs ps qs: List Pid)
    (H: ps.length = qs.length): List Pid :=
    match rs with
    | h::t => (pid_substs h ps qs H) :: (pids_substs t ps qs H)
    | [] => []
\end{verbatim}
\end{samepage}
Which are considered self-explanatory.\\
We also describe two helper lemmas:
\begin{samepage}
\begin{verbatim}
lemma helper23718 {G G': @SecCLab L} {qs ps ps': List Pid}
    (Hlen1: qs.length = ps.length)
    (Hlen2: qs.length = ps'.length):
    Disjoint qs.toFinset ps.toFinset
    -> Disjoint qs.toFinset ps'.toFinset
    -> List.Forall (lambda a => G (Prod.fst a) = G' (Prod.snd a))
                   (List.zip ps ps')
    -> gam_res_eq qs.toFinset (secclab_substs G qs ps Hlen1)
        (secclab_substs G' qs ps' Hlen2)
\end{verbatim}
\end{samepage}
This lemma says that, under correct disjointness conditions, parallel substitutions of security labels are determined purely by the \emph{position-wise} agreement of the labels being plugged in.
\begin{samepage}
\begin{verbatim}
lemma helper7489376 {fst snd ps qs Hlen} {rs: List Pid}:
    (fst, snd) in (rs.zip (pids_substs rs ps qs Hlen))
    -> (fst in rs) /\ snd = pid_substs fst ps qs Hlen
\end{verbatim}
\end{samepage}
This lemma captures the intended \emph{position-preserving} view of substitutions on pid lists.

Now that we have all the necessary background, we can look at the body of the proof:
\begin{samepage}
\begin{verbatim}
    intro Hdis1 Hdis2
    have Hdis3: Disjoint ss.toFinset
        (pids_substs rs ps qs Hlen1).toFinset
            := disjoint_of_substs2 Hdis1 Hdis2
    apply helper23718 _ _ Hdis1 Hdis3
    rw [List.forall_iff_forall_mem]
    intro a Ha
    cases a
    case mk fst snd =>
    simp
    rw [sec_substs_of_pid_substs]
    have A1 := helper7489376 Ha
    rw [And.right A1]
\end{verbatim}
\end{samepage}
And see that, basically, the conclusion follows from two main ideas. The first one is that disjointness of the process names lets us reason independently on every element of $\vec{q}$. The second one is triangular reasoning, which proves the equation in every possible case. 

\chapter{Conclusion}\label{chap:conclusion}
This thesis addressed the problem of enforcing confidentiality in choreographic programs. Within the broader landscape where choreographies are used to specify, verify, or synthesize the intended interactions of distributed systems, we focused on the complementary concern of \emph{information-flow security}: ensuring, \emph{by construction}, that a choreography does not leak secret information to public observers.

\medskip
\noindent\textbf{Summary of contributions.}
\begin{itemize}
  \item \emph{Policy-parametric type discipline for information flow.} We designed a compositional type system that is parametric in a security lattice $\MCL$. The typing judgement
  \[
    \Delta \;;\; \Gamma \;;\; \bot \;\vdash\; C
  \]
  checks a choreography $C$ under a flow policy $\Gamma$.
  The rules cover core choreographic constructs (communication, selection, conditional, and procedure call/definition) and ensure that low-observable behaviour cannot be influenced by high data or control.
  \item \emph{Soundness with respect to termination-insensitive non-interference.} We proved that well-typed choreographies satisfy non-interference with respect to a standard small-step reference semantics equipped with an attacker model that observes only $low$ effects. Formally, if $C$ is well-typed and two initial stores are indistinguishable at level $low$, then all $low$-observable outcomes of executing $C$ from those stores are indistinguishable. 
The proof hinges on a standard \emph{pc-discipline} for control-flow and a \emph{progress and preservation} argument over the choreographic reduction relation, and it is carried out for an arbitrary lattice $\MCL$.
  \item \emph{Procedure-context reconstruction.} We developed a reconstruction method that \emph{derives} the procedure context $\Delta$ by generating and solving well-formedness constraints extracted from the program. We proved that the reconstructed $\Delta$ is sound for typing (every reconstructed context is admissible).
  \item \emph{Mechanized metatheory.} All definitions and key metatheoretic results are mechanized in Lean. The development builds on ongoing work in mechanization of the theory of choreographic programming, thus the syntax and semantics referenced is imported into the project. The artifact attached to the thesis includes the policy-parametric type system with the program-counter discipline and the termination-insensitive non-interference theorem with the corresponding proof. The formalization reuses Mathlib's order-theoretic infrastructure to encode the abstract lattice $\MCL$, keeping the proofs generic in the security policy.
\end{itemize}
Taken together, these contributions show that non-interference can be enforced \emph{at the choreographic level} by a lightweight, compositional, type discipline and that the resulting guarantees are robust: they are independent of the particular security lattice, stable under recursion and procedure abstraction, and validated by a machine-checked proof. In this way, the thesis complements existing choreographic methodologies with principled confidentiality guarantees, bringing the clarity and modularity of choreography-based design to information-flow security.
\section{Extensions}
Multiple extensions from the work presented in this thesis are possible, and would be needed to have a \emph{complete} treatment of mechanized non-interference for choreographies. They are ordered by the descending importance that I personally attribute to them.
\begin{itemize}
\item \emph{Extend the coverage of the mechanization.} Given the time constraint, not every result reached in this work has been mechanized. An important extension would be to have the full coverage of the proofs presented in this document in the Lean artifact.
\item \emph{Completeness of the type inference algorithm with respect to the type relation.} In other words, this requires proving that every flow-policy that well types a choreography also satisfies the constraints found by the type-inference algorithm. This result would also make it possible for a programmer to \emph{underspecify} a flow-policy, leaving to the inference algorithm the job of finding a type for the \emph{working variables} that satisfies the constraints of the specified flow-policy.
\item \emph{Discriminating channels security.} The flow-policy can be extended to specify the security level of every channel between processes, so that private informations are not allowed on insecure channels.
\item \emph{Non-interference in the presence of non-determinism.} The choreographic language presented in \cite{montesi2023introduction} is extended in Chapter 10 to include \emph{non-deterministic choice}. Extensions of the notion of non-interference are present in the literature\cite{sabelfeld2003language}. It would be particularly interesting to explore their application to choreographic languages, since non-determinism can be seen as a key feature of distributed software systems.
\end{itemize}

\begin{appendices}
\chapter{Proofs on Syntactic Transformations}
\label{appdix:A}
\section{Sequential Composition and $\wr \cdot \wr$}
We need to prove the following:
$$\wr C_1 \fatsemi C_2 \wr = \wr C_1 \wr \fatsemi \wr C_2 \wr$$

\noindent\textbf{Proof:}
This proof follows by induction on $C_1$, unrolling the definitions of the operators involved.

\section{Process Substitution and $\wr \cdot \wr$}
We need to prove the following:
$$\wr C [\vec{q}/\vec{p}] \wr = \wr C \wr [\vec{q}/\vec{p}]$$

\noindent\textbf{Proof:}
This proof follows by induction on $C$, unrolling the definitions of the operators involved.

\section{Store Update and $\lfloor \cdot \rfloor$}
We need to prove the following:
$$\lfloor \Sigma \rfloor[p.x \mapsto v] = \lfloor \Sigma[p.x \mapsto [v]] \rfloor$$

\noindent\textbf{Proof:}
We defined equivalence between stores as extensional equivalence between maps.
This theorem follows from triangular reasoning:\\
For $q.y$ different from $p.x$:
\begin{align*}
&\lfloor \Sigma \rfloor[p.x \mapsto v]~q.y = \lfloor \Sigma \rfloor~q.y\\
&\lfloor \Sigma [p.x \mapsto [v]] \rfloor~q.y = \lfloor \Sigma \rfloor~q.y
\end{align*}
While simultaneously:
\begin{align*}
&\lfloor \Sigma \rfloor[p.x \mapsto v]~p.x = v\\
&\lfloor \Sigma [p.x \mapsto [v]] \rfloor~p.x = \lfloor [v] \rfloor = v
\end{align*}


\section{Process Substitution and $\lceil \cdot \rceil$}
We need to prove the following:
$$\wr C [\vec{q}/\vec{p}] \wr = \wr C \wr [\vec{q}/\vec{p}]$$

\noindent\textbf{Proof:}
This proof follows by induction on $C$, unrolling the definitions of the operators involved.


\chapter{Decomposition of Sequential Composition Execution}
\label{appdix:B}
\section{\textbf{[Chor]} Sequential Composition}
We start by proving the following lemma:
\begin{align}
\begin{split}
\label{appdix:Bskin}
&\langle C_1 ; C_2, \Sigma, \mathscr{C}\rangle \Downarrow \Sigma''\\
&\Rightarrow \exists \Sigma',
\langle C_1, \Sigma, \mathscr{C} \rangle \twoheadrightarrow \langle \boldsymbol{0}, \Sigma', \mathscr{C} \rangle 
\quad\land\quad
\langle C_2, \Sigma', \mathscr{C} \rangle \Downarrow \Sigma''
\end{split}
\end{align}

\noindent\textbf{Proof:}
We proceed by induction on $\cdot \Downarrow \cdot$
\begin{itemize}
\item \emph{case nil:} This case is not possible because there are no $C_1, C_2$ such that $\boldsymbol{0} = C_1; C_2$. Thus the goal follows by \emph{ex-falso quodlibet}.
\item \emph{case step:} the inductive case gives us the following hypothesis:
\begin{align}
&\langle C_1; C_2, \Sigma, \mathscr{C}\rangle \rightarrow
\langle C^\star, \Sigma^\star, \mathscr{C}\rangle \label{appdix:b1_h1} \tag{H1}\\
\begin{split}
&\forall C_1^\star~C_2^\star,\quad C^\star = C_1^\star; C_2^\star \\
&\Rightarrow \exists \Sigma^\heart,~\langle C_1^\star, \Sigma^\star, \mathscr{C}\rangle \rightarrow \langle \boldsymbol{0}, \Sigma^\heart, \mathscr{C}\rangle ~\land~ \langle C_2^\star, \Sigma^\heart, \mathscr{C}\rangle \Downarrow \Sigma'' \\
\end{split}\label{appdix:b1_ih}\tag{IH}
\end{align}
By inversion on (\ref{appdix:b1_h1}) we find two possible cases:
\begin{itemize}
\item $\langle C_1, \Sigma, \mathscr{C}\rangle \rightarrow
\langle C_1^\star, \Sigma^\star, \mathscr{C}\rangle$ with $C^\star = C_1^\star; C_2$
\item $\langle \boldsymbol{0}; C_2, \Sigma, \mathscr{C}\rangle \rightarrow
\langle C_2, \Sigma^\star, \mathscr{C}\rangle$ thus with $C^\star = C_2$
\end{itemize}
Both cases follow easily from the previous hypothesis. $\qed$
\end{itemize}


\section{\textbf{Chor} Sequential Composition}
We finally prove the following statement:
\begin{align}
\begin{split}
\label{appdix:Bfat}
&\langle \lceil C_1 \fatsemi C_2\rceil, \Sigma, \mathscr{C}\rangle \Downarrow \Sigma''\\
&\Rightarrow \exists \Sigma',
\langle \lceil C_1 \rceil, \Sigma, \mathscr{C} \rangle \twoheadrightarrow \langle \boldsymbol{0}, \Sigma', \mathscr{C} \rangle 
\quad\land\quad
\langle \lceil C_2 \rceil, \Sigma', \mathscr{C} \rangle \Downarrow \Sigma''
\end{split}
\end{align}

\noindent\textbf{Proof:}
We proceed by induction on $C_1$:
\begin{itemize}
\item \emph{case $\boldsymbol{0}$:} by definition of $\cdot \fatsemi \cdot$ we have that:
$$
\lceil C_1 \fatsemi C_2 \rceil = \lceil C_2 \rceil
$$
And the conclusion follows by reflexivity of $\cdot \twoheadrightarrow \cdot$, with $\Sigma' = \Sigma$
\item \emph{case $I_1; C_1'$:} As \emph{induction hypothesis} we have that, for all $\Sigma^\heart$
\begin{align*}
\begin{split}
\langle \lceil C_1' \fatsemi C_2\rceil, \Sigma^\heart, \mathscr{C}\rangle \Downarrow \Sigma''
\Rightarrow \exists \Sigma^\star,
\langle \lceil C_1' \rceil, \Sigma^\heart, \mathscr{C} \rangle \twoheadrightarrow \langle \boldsymbol{0}, \Sigma^\star, \mathscr{C} \rangle 
\quad\land\quad
\langle \lceil C_2 \rceil, \Sigma^\star, \mathscr{C} \rangle \Downarrow \Sigma''
\end{split}
\end{align*}
By definition of $\lceil \cdot \rceil, \cdot \fatsemi \cdot$ we have:
$$
\lceil C_1 \fatsemi C_2 \rceil = \lceil (I_1; C_1') \fatsemi C_2 \rceil =
\lceil I_1; (C_1' \fatsemi C_2) \rceil = \lceil I_1 \rceil; \lceil C_1' \fatsemi C_2 \rceil
$$
\end{itemize}
Using lemma (\ref{appdix:Bskin}) we find:
$$
\exists \Sigma^\heart,~\langle \lceil I_1 \rceil, \Sigma, \mathscr{C} \rangle \twoheadrightarrow \langle \boldsymbol{0}, \Sigma^\heart, \mathscr{C} \rangle ~\land~ \langle \lceil C_1' \fatsemi C_2 \rceil, \Sigma^\heart, \mathscr{C}\rangle \Downarrow \Sigma''
$$
Thus we prove the goal by choosing $\Sigma' = \Sigma^\star$ and constructing the following execution (the extension of the semantics rule for $\cdot;\cdot$ to $\cdot \twoheadrightarrow \cdot$ is assumed as obvious):
\begin{align*}
\langle \lceil I_1\rceil; \lceil C_1'\rceil, \Sigma, \mathscr{C}\rangle
&\twoheadrightarrow
\langle \boldsymbol{0}; \lceil C_1'\rceil, \Sigma^\heart, \mathscr{C}\rangle\\
\rightarrow \langle \lceil C_1' \rceil, \Sigma^\heart, \mathscr{C}\rangle
&\twoheadrightarrow \langle \boldsymbol{0}, \Sigma^\star, \mathscr{C}\rangle\\
	\land\quad \langle\lceil C_2 \rceil, \Sigma^\star,\mathscr{C}\rangle \Downarrow \Sigma''&
\end{align*}
$\qed$

\chapter{Helper Lemmas for Constraint Reconstruction}
\section{Monotonicity of $\upphi_\mathscr{C}$}
\label{appdix:rec:monotono}
To define and prove monotonicity we first need to define an order relation on \textbf{ProcConstr}. We define it as follows:
$$
\delta_1 \le \delta_2 \quad\triangleq\quad \forall X,~\delta_1~X\subseteq \delta_2~X
$$
By unrolling the definition of $\upphi_\mathscr{C}$ the reduce the proof of monotonicity to the following theorem:
$$
\delta_1 \le \delta_2~\land~ \delta_1,\eta\vdash C\rhd E_1 ~\land~\delta_2,\eta\vdash C\rhd E_2 \quad\Longrightarrow \quad E_1 \subseteq E_2
$$

\noindent\textbf{Proof:}\\
We proceed by structural induction on $C$. The majority of cases are trivial because the typing rules compute $E_1, E_2$ such that $E_1 = E_2$.\\
The only interesting case is $C = X(\vec{p})$. By inverting $\cdot \vdash \cdot \rhd \cdot$ we find:
$$
E_{X,1} \subseteq E_{X,2}
$$
Since $\subseteq$ is preserved by equal substitutions the conclusion holds. $\qed$

\section{Rewriting $\eta$ in \underline{cansolve}}
\label{appdix:rec:cansolve_pc}
We need to prove:
\begin{align*}
&\text{\underline{cansolve}}~E[\eta/\eta' \sqcup \Uppsi]~\Gamma~pc
\quad\land\quad (\forall pc', \llbracket \Uppsi \rrbracket~\Gamma~pc'=\ell)\\
&\Longrightarrow \text{\underline{cansolve}}~E~\Gamma~(pc\sqcup\ell)
\end{align*}

\noindent \textbf{Proof:}\\
By unfolding the definition of \underline{cansolve} we can reduce the theorem to the following:
$$
\llbracket \Uppsi^\star[\eta/\eta' \sqcup \Uppsi]\rrbracket~\Gamma~pc \sqsubseteq \Gamma~q.y~
\land (\forall pc', \llbracket \Uppsi \rrbracket~\Gamma~pc'=\ell)\Longrightarrow~
\llbracket \Uppsi^\star\rrbracket~\Gamma~(pc \sqcup \ell) \sqsubseteq \Gamma~q.y
$$
We proceed by induction on $\Uppsi^\star$:
\begin{itemize}
\item \emph{case bottom:} Trivial
\item \emph{case p.x:} 
$$
\llbracket p.x[\eta/\cdot]\rrbracket~\Gamma~pc =\llbracket p.x\rrbracket~\Gamma~pc' = \Gamma~p.x
$$
\item \emph{case $\eta$:} 
$$
\llbracket \eta[\eta/\eta' \sqcup \Uppsi]\rrbracket~\Gamma~pc =
\llbracket \eta' \sqcup \Uppsi \rrbracket~\Gamma~pc =
\llbracket \eta'\rrbracket~\Gamma~pc~\sqcup~
\llbracket \Uppsi \rrbracket~\Gamma~pc =
pc \sqcup \ell
$$
While simultaneously:
$$
\llbracket \eta\rrbracket~\Gamma~(pc\sqcup\ell) = pc \sqcup\ell
$$
\item \emph{case sup:} This case follows easily using the inductive hypothesis,\\
$\llbracket \Uppsi_1^\star \sqcup \Uppsi_2^\star \rrbracket = 
\llbracket \Uppsi_1^\star \rrbracket \sqcup \llbracket \Uppsi_2^\star \rrbracket \quad\text{and}\quad
(\Uppsi_1^\star \sqcup \Uppsi_2^\star)[\eta/\cdot]= 
\Uppsi_1^\star [\eta/\cdot]\sqcup \Uppsi_2^\star[\eta/\cdot]$
\end{itemize}

\section{Substitution in \underline{cansolve}}
\label{appdix:rec:cansolve_sub}
We need to show:
$$
\text{\underline{cansolve}}~E[\vec{q}/\vec{p}~]~\Gamma~pc
\Longrightarrow \text{\underline{cansolve}}~E~\Gamma[\vec{q}\mapsto\vec{p}~]~pc
$$

\noindent\textbf{Proof:}\\
For brevity we consider only the scalar case: the extension is trivial if $\vec{q}$ is taken sufficiently fresh (as assumed in \ref{ass:fresh}). By unfolding \underline{cansolve} we reduce the theorem to the following:
$$
\llbracket \Uppsi[q/p]\rrbracket~\Gamma~pc \sqsubseteq \Gamma~(r.y[q/p])
\Longrightarrow \llbracket \Uppsi\rrbracket~\Gamma[q\mapsto p]~pc \sqsubseteq \Gamma[q\mapsto p]~r.y
$$
We proceed by induction on the structure of $\Uppsi$:
\begin{itemize}
\item \emph{case bottom:} Trivial
\item \emph{case s.x:} We have:
$$
\llbracket s.x[q/p]\rrbracket~\Gamma~pc \sqsubseteq \Gamma~(r.y[q/p])
$$
Which by definition of $\llbracket \cdot \rrbracket$ can be rewritten into:
$$
\Gamma~(s.x[q/p]) \sqsubseteq \Gamma~(r.y[q/p])
$$
While simultaneously we have:
$$
\llbracket s.x\rrbracket~\Gamma[q\mapsto p]~pc \sqsubseteq \Gamma[q\mapsto p]~r.y
$$
Which can be rewritten into:
$$
\Gamma[q\mapsto p]~s.x \sqsubseteq \Gamma[q\mapsto p]~r.y
$$
The equation of the two constraints follows from the following lemma:
$$
\Gamma[q\mapsto p]~r = \Gamma~r[q/p]
$$
Which was proven in \emph{lean} as part of the proof of the unwinding lemma (\ref{aux:unw}).

\item \emph{case $\eta$:} Trivial
\item \emph{case sup:} This case follows easily using the inductive hypothesis,\\
$\llbracket \Uppsi_1^\star \sqcup \Uppsi_2^\star \rrbracket = 
\llbracket \Uppsi_1^\star \rrbracket \sqcup \llbracket \Uppsi_2^\star \rrbracket \quad\text{and}\quad
(\Uppsi_1^\star \sqcup \Uppsi_2^\star)[\eta/\cdot]= 
\Uppsi_1^\star [\eta/\cdot]\sqcup \Uppsi_2^\star[\eta/\cdot]$
\end{itemize}

\end{appendices}


\bibliographystyle{plain}
\bibliography{refs}

\chapter*{Acknowledgments}
Ringrazio la mia famiglia per avermi \emph{supportato} e i miei amici per avermi \emph{sopportato} tra Italia, Francia e Danimarca.

\noindent Ringrazio inoltre i miei supervisor Marco Peressotti e Saverio Giallorenzo per avermi a più riprese schiarito le idee sul miglior modo di affrontare i problemi presentatisi durante la progettazione e stesura di questa tesi.
Ringrazio Fabrizio Montesi e Xueying Qin per avermi aiutato a dimostrare in Lean lemmi ben al di sopra della mia capacità.
\end{document}
